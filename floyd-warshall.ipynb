{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! mkdir include\n! mkdir src\n! mkdir bin\n! mkdir csv","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:31.031030Z","iopub.execute_input":"2022-08-20T10:29:31.031407Z","iopub.status.idle":"2022-08-20T10:29:34.957628Z","shell.execute_reply.started":"2022-08-20T10:29:31.031362Z","shell.execute_reply":"2022-08-20T10:29:34.956460Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"%%file Makefile\n\n#compilare con:\n#make dev VERSION=1_1\n\n#compilers\nNVCC=nvcc\nGXX=g++\n\n#directories\nsrc_path=src\nheader_path=include\n\ndev:\n\t@echo \"version:\" $(VERSION)\n\tnvcc -rdc=true -o bin/fwa_dev_v_$(VERSION).out \\\n\t\tdevice_floyd_warshall_v_$(VERSION).cu \\\n\t\tsrc/adj_matrix_utils.cu \\\n\t\tsrc/adj_matrix_utils.cpp \\\n\t\tsrc/cuda_errors_utils.cu \\\n\t\tsrc/generate_n_b_couples.cpp \\\n\t\tsrc/handle_arguments_and_execute.cu \\\n\t\tsrc/host_floyd_warshall.cpp \\\n\t\tsrc/performance_test.cu \\\n\t\tsrc/statistical_test.cpp\n\nread_matrix :\t\n\tnvcc -rdc=true -o bin/read_matrix.out \\\n\t\tmain.cpp \\\n\t\tsrc/adj_matrix_reader.cpp \\\n\t\tsrc/adj_matrix_utils.cpp\n\nfwm:\n\tg++ -o bin/fwm.out \\\n\t\thost_floyd_warshall_matrix.cpp \\\n\t\tsrc/adj_matrix_utils.cpp  \\\n\t\tsrc/host_floyd_warshall.cpp \\\n\nfwa:\n\tg++ -o bin/fwa.out \\\n\t\thost_floyd_warshall_array.cpp \\\n\t\tsrc/adj_matrix_utils.cpp \\\n\t\tsrc/host_floyd_warshall.cpp\n\ndev_test:\n\tnvcc -rdc=true -o bin/dev_test.out \\\n\t\tdevice_test.cu \\\n\t\tsrc/cuda_errors_utils.cu\n\ngenerate_n_b:\n\tg++ -o bin/generate_and_print_n_b.out \\\n\t\tgenerate_and_print_n_b.cpp \\\n\t\tsrc/generate_n_b_couples.cpp","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:34.959892Z","iopub.execute_input":"2022-08-20T10:29:34.960575Z","iopub.status.idle":"2022-08-20T10:29:34.969555Z","shell.execute_reply.started":"2022-08-20T10:29:34.960543Z","shell.execute_reply":"2022-08-20T10:29:34.968432Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"%%file include/adj_matrix_reader.hpp\n\n#ifndef ADJ_MATRIX_READER_HPP\n#define ADJ_MATRIX_READER_HPP\n\n#include <string>\n\n/// <summary>\n/// Leggi un file CSV contenente una matrice di adiacenza.\n/// </summary>\n/// <param name=\"filename\">Il nome del file da leggere</param>\n/// <param name=\"delim\">Il delimitatore del file CSV</param>\n/// <param name=\"adjMatrix\">Un puntatore vuoto dove verrï¿½ allocata la memoria per mem. la matrice</param>\n/// <param name=\"numberOfNodes\">Il numero di nodi del grafo (corrisponde al numero di righe e colonne della matrice)</param>\n/// <return>0 if okay, else something less</return>\nint** readAdjMatrixCSV(std::string filename, const char delim, int* numberOfNodes);\n\n#endif\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-08-20T10:29:34.971788Z","iopub.execute_input":"2022-08-20T10:29:34.972324Z","iopub.status.idle":"2022-08-20T10:29:34.982926Z","shell.execute_reply.started":"2022-08-20T10:29:34.972289Z","shell.execute_reply":"2022-08-20T10:29:34.982001Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"%%file include/adj_matrix_utils.cuh\n\n#ifndef ADJ_MATRIX_UTILS_CUH\n#define ADJ_MATRIX_UTILS_CUH\n\n//  PRINT UTILS\n\n#include \"macros.hpp\"\n\n__device__ void print_matrix_device(int *matrix, int m, int n, int pitch);\n\n\n#endif // ADJ_MATRIX_UTILS_CUH","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:34.985986Z","iopub.execute_input":"2022-08-20T10:29:34.987106Z","iopub.status.idle":"2022-08-20T10:29:34.993258Z","shell.execute_reply.started":"2022-08-20T10:29:34.987072Z","shell.execute_reply":"2022-08-20T10:29:34.992172Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"%%file include/adj_matrix_utils.hpp\n\n#ifndef ADJ_MATRIX_UTILS_HPP\n#define ADJ_MATRIX_UTILS_HPP\n\n#include <stdbool.h>\n\n#include \"macros.hpp\"\n\n/// Parameters used when generating a graph\n#define DENSITY 60\n#define MIN_COST 1\n#define MAX_COST 20\n\n// ---------------------------------------------------------------\n//  PRINT UTILS\n\nvoid print_array(int *array, int size);\nvoid print_matrix(int **matrix, int m, int n);\nvoid print_element(int val, int infinity);\nvoid print_arr_matrix(int *matrix, int m, int n);\n\n// ---------------------------------------------------------------\n// MATRIX GENERATION, COMPARE and others utils\n\nint** allocate_matrix(int m, int n);\nvoid populate_adj_matrix(int **matrix, int n, int seed, bool oriented_graph);\nbool same_matrixes(int **matrix_1, int **matrix_2, int m, int n, bool oriented_graph);\n\n// ---------------------------------------------------------------\n// ARRAY MATRIX FUNCTIONS VARIANTS\n\nint* allocate_arr_matrix(int m, int n);\nvoid populate_arr_adj_matrix(int* arr_matrix, int n, int seed, bool oriented_graph);\nbool same_arr_matrixes(int *matrix_1, int *matrix_2, int m, int n, bool oriented_graph);\n\n#endif // ADJ_MATRIX_UTILS_H","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:34.995467Z","iopub.execute_input":"2022-08-20T10:29:34.995807Z","iopub.status.idle":"2022-08-20T10:29:35.004900Z","shell.execute_reply.started":"2022-08-20T10:29:34.995773Z","shell.execute_reply":"2022-08-20T10:29:35.003728Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"%%file include/cuda_errors_utils.cuh\n\n#ifndef CUDA_ERRORS_UTILS_CUH\n#define CUDA_ERRORS_UTILS_CUH\n\n\n#define HANDLE_ERROR(err) (handle_error(err, __FILE__, __LINE__))\n\nvoid handle_error(cudaError_t err, const char *file, int line);\n\nvoid check_CUDA_error(const char *msg);\n\n#endif","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.006421Z","iopub.execute_input":"2022-08-20T10:29:35.006905Z","iopub.status.idle":"2022-08-20T10:29:35.015152Z","shell.execute_reply.started":"2022-08-20T10:29:35.006868Z","shell.execute_reply":"2022-08-20T10:29:35.014037Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"%%file include/generate_n_b_couples.hpp\n\n#ifndef GENERATE_N_B_COUPLES\n#define GENERATE_N_B_COUPLES\n\n// c++ libraries\n// for std::vector\n#include <vector>\n// for std::pair\n#include <utility>\n// for std::string\n#include <string>\n\n// generate the list of couples (n,b)\nstd::vector<std::pair<int, int>> generate_list_of_all_n_b(int min_input_size, int max_input_size, int max_num_of_b_per_n, double to_multiply, int to_sum, int min_blocking_factor, int max_num_tests, int seed);\n\n// prints to file the list of couples (n,b)\nvoid print_list_to_file(std::vector<std::pair<int, int>> list_of_all_n_b, std::string filename);\n\n// MACROS \n\n// DEFAULT VALUES:\n// returns a random number between 1.300 and 1.600\n#define OBTAIN_VAL_TO_MULTIPLY(rand_value) ((double) ((rand_value % 300) + 1300)) / ((double) 1000)\n// outputs a random even number between 0 and 100\n#define OBTAIN_VAL_TO_SUM(rand_value) ((rand_value % 101) * 2)\n\n#endif //GENERATE_N_B_COUPLES\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.016795Z","iopub.execute_input":"2022-08-20T10:29:35.017521Z","iopub.status.idle":"2022-08-20T10:29:35.024447Z","shell.execute_reply.started":"2022-08-20T10:29:35.017486Z","shell.execute_reply":"2022-08-20T10:29:35.023232Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"%%file include/handle_arguments_and_execute.cuh\n\n#ifndef HANDLE_ARGUMENTS_AND_EXECUTE\n#define HANDLE_ARGUMENTS_AND_EXECUTE\n\nint handle_arguments_and_execute(int argc, char *argv[], void (*f) (int* arr_matrix, int n, int b));\n\n#endif //HANDLE_ARGUMENTS_AND_EXECUTE\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.026264Z","iopub.execute_input":"2022-08-20T10:29:35.026954Z","iopub.status.idle":"2022-08-20T10:29:35.037331Z","shell.execute_reply.started":"2022-08-20T10:29:35.026918Z","shell.execute_reply":"2022-08-20T10:29:35.036430Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"%%file include/host_floyd_warshall.hpp\n\n#ifndef HOST_FLOYD_WARSHALL\n#define HOST_FLOYD_WARSHALL\n\n\n#include \"macros.hpp\"\n\n// ---------------------------------------------------------------------------\n// Matrix data structure version\n\nvoid host_matrix_floyd_warshall(int **matrix, int n);\nvoid host_matrix_floyd_warshall_blocked(int **matrix, int n, int B);\nvoid host_matrix_execute_round(int **matrix, int n, int t, int row, int col, int B);\n\n// ---------------------------------------------------------------------------\n// Array data structure version\n\nvoid host_array_floyd_warshall(int *matrix, int n);\nvoid host_array_floyd_warshall_blocked(int *matrix, int n, int B);\nvoid host_array_execute_round(int *matrix, int n, int t, int row, int col, int B);\n\n#endif","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.038932Z","iopub.execute_input":"2022-08-20T10:29:35.039641Z","iopub.status.idle":"2022-08-20T10:29:35.047854Z","shell.execute_reply.started":"2022-08-20T10:29:35.039607Z","shell.execute_reply":"2022-08-20T10:29:35.046810Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"%%file include/include_needed_libraries.cuh\n\n// c libraries\n#include <stdio.h>\n\n// c++ libraries\n// for assertions\n#include <cassert>\n\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n\n#include \"adj_matrix_utils.cuh\"\n#include \"adj_matrix_utils.hpp\"\n#include \"cuda_errors_utils.cuh\"\n#include \"handle_arguments_and_execute.cuh\"\n#include \"host_floyd_warshall.hpp\"\n#include \"macros.hpp\"\n#include \"performance_test.cuh\"\n#include \"statistical_test.hpp\"","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.052734Z","iopub.execute_input":"2022-08-20T10:29:35.052989Z","iopub.status.idle":"2022-08-20T10:29:35.059921Z","shell.execute_reply.started":"2022-08-20T10:29:35.052966Z","shell.execute_reply":"2022-08-20T10:29:35.058848Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"%%file include/lcm.hpp\n\n#ifndef LCM_HPP\n#define LCM_HPP\n\nint lcm(int x, int y) {\n\n    int r=0;\n\n    while (r%x!=0 || r%y!=0) {\n        r++;\n    }\n    \n    return r;\n}\n\n#endif","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.061681Z","iopub.execute_input":"2022-08-20T10:29:35.062332Z","iopub.status.idle":"2022-08-20T10:29:35.069268Z","shell.execute_reply.started":"2022-08-20T10:29:35.062297Z","shell.execute_reply":"2022-08-20T10:29:35.068194Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"%%file include/macros.hpp\n\n#ifndef MACROS_HPP\n#define MACROS_HPP\n\n/// Big M, value that should be threated as \"infinity\"\n#define INF __INT16_MAX__\n\n/// Get minimum or maximum of two values\n// renamed from min and max to avoid overload with std::mmin and std::mmax\n#define mmin(a,b) ((a < b) ? a : b)\n#define mmax(a,b) ((a > b) ? a : b)\n\n/// Sum two numbers if they are not infinite, else return infinity\n#define sum_if_not_infinite(x1,x2,infinity) ((x1==infinity) || (x2==infinity)) ? infinity : (x1+x2)\n\n\n#define MAX_BLOCK_SIZE 1024 // in realtÃ  basta fare le proprerties della macchina\n#define MAX_BLOCKING_FACTOR 32 // 32*32 = 1024\n\n/// Macro to get block starting position (of a column or of a row)\n#define BLOCK_START(block_index,B) (block_index * B)\n\n/// Macro to get block ending position (of a column or of a row)\n#define BLOCK_END(block_index,B) ((block_index+1) * B)\n\n/// Print a bool as a string\n#define bool_to_string(cond) (cond ? \"true\" : \"false\")\n\n/// returns the pointer of given (i,j) using the access pattern of a 2D pitched memory\n#define pitched_pointer(matrix, i, j, pitch) ( (int *) (((char*) matrix + i * pitch) + j) )\n\n\n#endif","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.071069Z","iopub.execute_input":"2022-08-20T10:29:35.071806Z","iopub.status.idle":"2022-08-20T10:29:35.079707Z","shell.execute_reply.started":"2022-08-20T10:29:35.071771Z","shell.execute_reply":"2022-08-20T10:29:35.078447Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"%%file include/performance_test.cuh\n\n#ifndef PERFORMANCE_TEST_CUH\n#define PERFORMANCE_TEST_CUH\n\nvoid do_nvprof_performance_test(void (*floyd_warshall_arr_algorithm)(int * matrix, int n, int B), int input_size, int blocking_factor, int number_of_tests, int seed);\n\n#endif","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.081407Z","iopub.execute_input":"2022-08-20T10:29:35.081848Z","iopub.status.idle":"2022-08-20T10:29:35.092769Z","shell.execute_reply.started":"2022-08-20T10:29:35.081812Z","shell.execute_reply":"2022-08-20T10:29:35.091779Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"%%file include/statistical_test.hpp\n\n#ifndef STATISTICAL_TEST_HPP\n#define STATISTICAL_TEST_HPP\n\n#define RANDOM_SEED     0\n#define RANDOM_CONSTANT -1\n\n\nstruct MultiSizeTestParameters {\n    void (*f) (int* arr_matrix, int n, int b) = NULL;   // test function\n    void (*g) (int* arr_matrix, int n, int b) = NULL;   // compare function\n    int start_input_size        = 4;                    // min n to test\n    int end_input_size          = 1024;                 // max n to test\n    double to_multiply          = RANDOM_CONSTANT;      // used to linearly increase input size: { next_size = cur_size * to_multiply + to_sum } (pass RANDOM_CONSTANT to generate a random value)\n    int to_sum                  = RANDOM_CONSTANT;      // used to linearly increase input size: { next_size = cur_size * to_multiply + to_sum } (pass RANDOM_CONSTANT to generate a random value)\n    int seed                    = RANDOM_SEED;          // seed for input generation (pass RANDOM_SEED to generate a random seed)\n    int n_tests_per_round       = 500;                  // number of different test foreach given couple (n,B)\n    int print_progress_perc     = 1;                    // print progress of a test for a given couple (n,B) (for ex. 4 ==> 100/4 = 25% ==> print progress at 25%, 50%, 75%), if 1 is disabled\n    bool stop_current_if_fail   = true;                 // true ==> if found an error for a given couple (n,B): stop test this couple but keep testing other couples\n    bool stop_all_if_fail       = false;                // true ==> if found an error for a given couple (n,B): stop all tests (return control) (NB: stop_all_if_fail ==> stop_current_if_fail but not viceversa)\n    bool print_failed_tests     = true;                 // true ==> if found an error print seed and the index of the test\n    int min_blocking_factor     = 2;                    // the minimum blocking factor you are intrested testing\n};\n\n// generates many couples (n,B) and foreach couple generates inputs and executes executes f,g n_tests_per_round times\n// returns: total number of errors of all couples\nint  multi_size_statistical_test(MultiSizeTestParameters params);\nvoid print_multi_size_test_parameters(MultiSizeTestParameters params);\n\n// -------------------------------------------------------------------------------------------------\n\nstruct CallSingleSizeTestParameters {\n    void (*f) (int* arr_matrix, int n, int b) = NULL;   // test function\n    void (*g) (int* arr_matrix, int n, int b) = NULL;   // compare function\n    int input_size              = 256;                  // input test size\n    int blocking_factor         = 12;                   // blocking factor test size\n    int seed                    = RANDOM_SEED;          // seed for input generation (pass RANDOM_SEED to generate a random seed)\n    int n_tests                 = 500;                  // number of different tests to do\n    int print_progress_perc     = 1;                    // print progress of a test for a given couple (n,B) (for ex. 4 ==> 100/4 = 25% ==> print progress at 25%, 50%, 75%), if 1 is disabled\n    bool stop_current_if_fail   = true;                 // true ==> if found an error: stop testing (return control)\n    bool print_failed_tests     = true;                 // true ==> if found an error print seed and the index of the test\n};\n\n// given a couple (n,B), generates inputs and executes f,g n_tests_per_round times\n// returns: total number of errors of the given couple\nint  call_single_size_statistical_test(CallSingleSizeTestParameters params);\nvoid print_call_single_size_statistical_test_parameters(CallSingleSizeTestParameters params);\n    \n// -------------------------------------------------------------------------------------------------\n\nstruct ExecSingleSizeTestParameters {\n    void (*f) (int* arr_matrix, int n, int b) = NULL;   // test function\n    void (*g) (int* arr_matrix, int n, int b) = NULL;   // compare function\n    int input_size              = 256;                  // input test size\n    int blocking_factor         = 12;                   // blocking factor test size\n    int *input_instance         = NULL;                 // input instance populated\n};\n\n// given a couple (n,B) and an an input instance populated executes f,g 1 time\n// returns: f(input) == g(input)\nbool exec_single_single_statistical_test(ExecSingleSizeTestParameters params);\nvoid print_exec_single_size_statistical_test_parameters(ExecSingleSizeTestParameters params);\n\n#endif","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.095053Z","iopub.execute_input":"2022-08-20T10:29:35.095569Z","iopub.status.idle":"2022-08-20T10:29:35.104576Z","shell.execute_reply.started":"2022-08-20T10:29:35.095534Z","shell.execute_reply":"2022-08-20T10:29:35.103591Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# END HEADER REGION\n# ----------------------------------------------------------------------------------------------------------------------------------------\n# START SRC REGION","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.105766Z","iopub.execute_input":"2022-08-20T10:29:35.106922Z","iopub.status.idle":"2022-08-20T10:29:35.115757Z","shell.execute_reply.started":"2022-08-20T10:29:35.106887Z","shell.execute_reply":"2022-08-20T10:29:35.114867Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"%%file src/adj_matrix_reader.cpp\n\n#include <fstream>\n#include <sstream>\n#include <iostream>\n\n#include \"../include/adj_matrix_reader.hpp\"\n\nint _getNumberOfNodes(std::string adjMatrixLine, const char delim) {\n\n\t// insipired to: https://java2blog.com/split-string-space-cpp/#Using_getline_Method\n\n\tstd::istringstream ss(adjMatrixLine);\n\n\tint nodesCounter = 0;\n\n\tstd::string s;\n\twhile (std::getline(ss, s, delim)) {\n\t\tnodesCounter++;\n\t}\n\n\treturn nodesCounter;\n}\n\nint _parseLine(std::string adjMatrixLine, const char delim, int lineNumber, int** adjMatrix) {\n\n\t// insipired to: https://java2blog.com/split-string-space-cpp/#Using_getline_Method\n\n\tstd::istringstream ss(adjMatrixLine);\n\tstd::string itemStr;\n\n\tint i = 0;\n\twhile (std::getline(ss, itemStr, delim)) {\n\n\t\tint value = std::stoi(itemStr);\n\t\tadjMatrix[lineNumber][i] = value;\n\n\t\ti++;\n\t}\n\n\treturn 0;\n}\n\n\nint** readAdjMatrixCSV(const std::string filename, const char delim, int *numberOfNodes) {\n\n\tstd::ifstream fs(filename);\n\t\n\tif (!fs.is_open()) {\n\t\t// todo: add error\n\t}\n\t\n\tif (fs.eof()) {\n\t\t// todo: add error\n\t}\n\n\t// read first line\n\tstd::string line;\n\tstd::getline(fs, line);\n\tint lineNumber = 0;\n\t\n\t// get number of nodes\n\t*numberOfNodes = _getNumberOfNodes(line, delim);\n\n\t// allocate memory for matrix\n\tint** adjMatrix = (int **) malloc(sizeof(int*) * (*numberOfNodes));\n\n\t// parse all lines and fill adjMatrix\n\tdo {\n\t\tadjMatrix[lineNumber] = (int*) malloc(sizeof(int) * (*numberOfNodes));\n\t\t_parseLine(line, delim, lineNumber, adjMatrix);\n\t\tlineNumber++;\n\t} while (std::getline(fs, line));\n\n\treturn adjMatrix;\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.118247Z","iopub.execute_input":"2022-08-20T10:29:35.119603Z","iopub.status.idle":"2022-08-20T10:29:35.128213Z","shell.execute_reply.started":"2022-08-20T10:29:35.119569Z","shell.execute_reply":"2022-08-20T10:29:35.127050Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"%%file src/adj_matrix_utils.cpp\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\n#include \"../include/adj_matrix_utils.hpp\"\n\n// ---------------------------------------------------------------\n//  PRINT UTILS\n\nvoid print_matrix(int **matrix, int m, int n) {\n    printf(\"[\\n\");\n    for (int i = 0; i < m; i++) {\n        printf(\"  \");\n        print_array(matrix[i], n);\n    }\n    printf(\"]\\n\");\n}\n\nvoid print_array(int *array, int size) {\n    printf(\"[\");\n    for (int i = 0; i < size; i++) {\n        print_element(array[i], INF);\n        if (i < size-1) printf(\", \");\n    }\n    printf(\"]\\n\");\n}\n\nvoid print_element(int val, int infinity) {\n    if (val < infinity)\n        printf(\"%02d\", val);\n    else \n        printf(\"--\");\n}\n\n// ---------------------------------------------------------------\n// MATRIX GENERATION, COMPARE and others utils\n\nbool same_matrixes(int **matrix_1, int **matrix_2, int m, int n, bool oriented_graph) {\n    for (int i = 0; i < m; i++) {\n        for (int j = oriented_graph ? 0 : (i+1); j < n; j++) {\n            if(matrix_1[i][j] != matrix_2[i][j]) return false;\n        }\n    }\n    return true;\n}\n\nint** allocate_matrix(int m, int n) {\n    //matrix with row major order:\n    //m rows pointers\n    int** matrix = (int **) malloc(sizeof(int *) * m);\n    for (int i = 0; i < m; i++) {\n        //each row has n intengers\n        matrix[i] = (int *) malloc(sizeof(int) * n);\n    }\n    return matrix;\n}\n\nvoid populate_adj_matrix(int **matrix, int n, int seed, bool oriented_graph) {\n    for (int i = 0; i < n; i++) {\n        //diagonal always zero (distance 0 to myself)\n        matrix[i][i] = 0;\n        for (int j = oriented_graph ? 0 : (i+1); j < n; j++) {\n            if (i != j) {               \n                bool add_edge = (rand() % 100) <= DENSITY;\n                int val = (rand() % MAX_COST) + MIN_COST;\n                matrix[i][j] = add_edge ? val : INF;\n                if (! oriented_graph) {\n                    //non-oriented graph\n                    matrix[j][i] = matrix[i][j];\n                }        \n            }\n        }\n    }\n}\n\n// ---------------------------------------------------------------\n// ARRAY MATRIX FUNCTIONS VARIANTS\n\nvoid print_arr_matrix(int *matrix, int m, int n) {\n    printf(\"[\\n\");\n    for (int i = 0; i < m; i++) {\n        printf(\"  \");\n        print_array(&(matrix[i*n]), n);\n    }\n    printf(\"]\\n\");\n}\n\nbool same_arr_matrixes(int *matrix_1, int *matrix_2, int m, int n, bool oriented_graph) {\n    for (int i = 0; i < m; i++) {\n        for (int j = oriented_graph ? 0 : (i+1); j < n; j++) {\n            if(matrix_1[i*n + j] != matrix_2[i*n + j]) return false;\n        }\n    }\n    return true;\n}\n\nint* allocate_arr_matrix(int m, int n) {\n    return (int *) malloc(sizeof(int) * m * n);\n}\n\nvoid populate_arr_adj_matrix(int* arr_matrix, int n, int seed, bool oriented_graph) {\n    for (int i = 0; i < n; i++) {\n        arr_matrix[i*n + i] = 0;\n        for (int j = oriented_graph ? 0 : (i+1); j < n; j++) {\n            if (i != j) {        \n                bool add_edge = (rand() % 100) <= DENSITY;\n                int val = (rand() % MAX_COST) + MIN_COST;\n                arr_matrix[i*n + j] = add_edge ? val : INF;\n                if (! oriented_graph) {\n                    //non-oriented graph\n                    arr_matrix[j*n + i] = arr_matrix[i*n + j];\n                }\n            }\n        }\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.129831Z","iopub.execute_input":"2022-08-20T10:29:35.130411Z","iopub.status.idle":"2022-08-20T10:29:35.139426Z","shell.execute_reply.started":"2022-08-20T10:29:35.130356Z","shell.execute_reply":"2022-08-20T10:29:35.138450Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"%%file src/adj_matrix_utils.cu\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\n#include \"../include/adj_matrix_utils.cuh\"\n\n__device__ void print_matrix_device(int *matrix, int m, int n, int pitch) {\n    printf(\"[\\n\");\n    for (int i = 0; i < m; i++) {\n        printf(\"  \");\n        for (int j = 0; j < n; j++) {\n            int val;\n            if (pitch == 0) {\n                val = matrix[i*n + j];\n            } else {\n                int* temp = pitched_pointer(matrix, i, j, pitch);\n                val = *temp;\n            }\n            if (val < INF)\n                printf(\"%02d\", val);\n            else \n                printf(\"--\");\n            if (j < n-1) printf(\", \");\n        }\n        printf(\"\\n\");\n    }\n    printf(\"]\\n\");\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.140917Z","iopub.execute_input":"2022-08-20T10:29:35.141299Z","iopub.status.idle":"2022-08-20T10:29:35.151959Z","shell.execute_reply.started":"2022-08-20T10:29:35.141264Z","shell.execute_reply":"2022-08-20T10:29:35.150831Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"%%file src/cuda_errors_utils.cu\n\n#include <stdio.h>\n\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n\n#include \"../include/cuda_errors_utils.cuh\"\n\nvoid handle_error(cudaError_t err, const char *file, int line) {\n    if (err != cudaSuccess) {\n        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ), file, line );\n        exit(EXIT_FAILURE);\n    }\n}\n\nvoid check_CUDA_error(const char *msg) {\n    cudaError_t err = cudaGetLastError();\n    if(cudaSuccess != err) {\n        fprintf(stderr, \"ERRORE CUDA: >%s<: >%s<. Eseguo: EXIT\\n\", msg, cudaGetErrorString(err) );\n        exit(-1);\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.153797Z","iopub.execute_input":"2022-08-20T10:29:35.154478Z","iopub.status.idle":"2022-08-20T10:29:35.165086Z","shell.execute_reply.started":"2022-08-20T10:29:35.154424Z","shell.execute_reply":"2022-08-20T10:29:35.164230Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"%%file src/generate_n_b_couples.cpp\n\n#include \"../include/generate_n_b_couples.hpp\"\n#include \"../include/macros.hpp\"\n\n// c library\n// for srand() and rand()\n#include <time.h>\n#include <stdlib.h>\n\n// c++ library for file stream\n#include <fstream>\n\nstd::vector<std::pair<int, int>> generate_list_of_all_n_b(int min_input_size, int max_input_size, int max_num_of_b_per_n, double to_multiply, int to_sum, int min_blocking_factor, int max_num_tests, int seed) {\n\n    // initialize seed\n    srand(seed);\n\n    std::vector<std::pair<int, int>> list_of_all_n_b;\n\n    for (int n = min_input_size; n <= max_input_size; n = mmax(((int) (to_multiply * (double) n)) + to_sum, (n+1)) ) {\n\n        // use mmax 5 different blocking factors\n        int B_used[max_num_of_b_per_n];\n        // initially all are -1\n        for (int i = 0; i < max_num_of_b_per_n; i++) B_used[i] = -1;\n\n        // index of the currently used B \n        int cur_B_idx = -1;\n\n        // generate randomly B check if it is a divisor of n and not already used.\n        // generate maximum max_num_tests random B (necessary to avoid non-termination, maybe n is prime)\n        for (int tests = 0; tests < max_num_tests && cur_B_idx < max_num_of_b_per_n; tests++) {\n\n            // range for b is between 0 and n/2\n            int B = rand() % mmin(n/2, MAX_BLOCKING_FACTOR);\n            // but if it is zero then use B=n\n            B = (B == 0) ? n : B;\n\n            // test if it is ok to be executed (b is a new divisor)\n            bool is_ok = (n % B == 0) && (B <= MAX_BLOCKING_FACTOR) && (B >= min_blocking_factor); \n            for (int i = 0; (i <= cur_B_idx) && is_ok; i++) is_ok = (B != B_used[i]);\n\n            if (is_ok) {\n                B_used[++cur_B_idx] = B;\n                list_of_all_n_b.push_back(std::make_pair(n, B));\n                //printf(\"n: %d, b: %d\\n\", n, B);\n            }\n        }\n    }\n\n    return list_of_all_n_b;\n}\n\nvoid print_list_to_file(std::vector<std::pair<int, int>> list_of_all_n_b, std::string filename) {\n\n    std::ofstream myfile;\n    myfile.open(filename);\n    myfile << \"n,b\\n\";\n        \n    for (int i = 0; i < list_of_all_n_b.size(); i++) {\n\n        int n = list_of_all_n_b[i].first;\n        int b = list_of_all_n_b[i].second;\n        myfile << n << \",\" << b << \"\\n\";\n    }\n    myfile.close();\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.168546Z","iopub.execute_input":"2022-08-20T10:29:35.168895Z","iopub.status.idle":"2022-08-20T10:29:35.177041Z","shell.execute_reply.started":"2022-08-20T10:29:35.168868Z","shell.execute_reply":"2022-08-20T10:29:35.175864Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"%%file src/handle_arguments_and_execute.cu\n\n#include \"../include/adj_matrix_utils.cuh\"\n#include \"../include/adj_matrix_utils.hpp\"\n#include \"../include/cuda_errors_utils.cuh\"\n#include \"../include/host_floyd_warshall.hpp\"\n#include \"../include/macros.hpp\"\n#include \"../include/performance_test.cuh\"\n#include \"../include/statistical_test.hpp\"\n\n// c libraries\n// for printing\n#include <stdio.h>\n// to define a seed using current time with time(NULL)\n#include <time.h>\n// for pseudo-random generation with srand() for seed initialization and rand() for pseudo-random number\n#include <stdlib.h>\n\n// c++ libraries\n// for argv handling as vector of string\n#include <string>\n#include <vector>\n\nint handle_arguments_and_execute(int argc, char *argv[], void (*f) (int* arr_matrix, int n, int b)) {\n\n    std::vector<std::string> str_args(argv, argv + argc);\n\n    std::string exec_option;\n    if (argc > 1) exec_option = str_args[1];\n\n    if (argc == 1 || exec_option == \"--help\") {\n        printf(\"Usage: %s <exec_option> [-n=<n>, -b=<b>, -t=<t> [-s=<s>]]:\\n\", argv[0]);\n        printf(\" where <exec_option>=test for statistical testing or <exec_option>=perf for nvprof profiling\\n\");\n        printf(\"If <exec_option>=perf then specify n (matrix dimension), b (blocking factor), t (number of tests), [ s (seed), by default is random ]\\n\");\n        return 1;\n    }\n\n    if (exec_option == \"test\") {\n\n        MultiSizeTestParameters my_params;\n        my_params.f = f;\n        my_params.g = &host_array_floyd_warshall_blocked;\n        my_params.start_input_size = 30;\n        my_params.end_input_size = 150;\n        my_params.to_multiply = RANDOM_CONSTANT;\n        my_params.to_sum      = RANDOM_CONSTANT;\n        my_params.min_blocking_factor = 2;\n\n        print_multi_size_test_parameters(my_params);\n        multi_size_statistical_test(my_params);\n        \n\n    } else if (exec_option == \"perf\") {\n        \n        int n = -1, b = -1, t = -1, s = -1;\n        if (str_args.size() < 5) {\n            printf(\"Missing n,t,b parameters\\n\");\n            return 2;\n        }\n        for (int i = 2; i < argc; i++) {\n            if(str_args[i].size() < 4) {\n                //mmin size for n,b,t parameters is 4 (ex. -n=5)\n                printf(\"Uncorrect syntax parameter, use -<param>=<value>\\n\");\n                return 3;\n            }\n            if(str_args[i][0] == '-' && str_args[i][2] == '=') {\n                int val = std::stoi((str_args[i]).substr(3));\n                if(     str_args[i][1] == 'n') n = val; // mandatory: matrix size\n                else if(str_args[i][1] == 'b') b = val; // mandatory: blocking factor size\n                else if(str_args[i][1] == 't') t = val; // mandatory: number of tests to execute\n                else if(str_args[i][1] == 's') s = val; // optional:  seed\n                else {\n                    printf(\"Parameter not recognised\\n\");\n                    return 4;\n                }\n            } \n        }\n        if (n <= 0 || b <= 0 || t <= 0) {\n            printf(\"n, b, t must all be specified and must be positive integers\\n\");\n            return 5;\n        }\n        if ((b > n) || (n % b > 0)) {\n            printf(\"b must be a divisor of n\\n\");\n            return 6;\n        }\n        if (s == -1) s = time(NULL);\n        printf(\"seed: %d\\n\", s);\n        do_nvprof_performance_test(f, n, b, t, s);\n\n    } else {\n        printf(\"<exec_option>=%s not recognised, try run: %s --help\\n\", argv[1], argv[0]);\n        return 7;\n    }\n\n    return 0;\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.179390Z","iopub.execute_input":"2022-08-20T10:29:35.180608Z","iopub.status.idle":"2022-08-20T10:29:35.189325Z","shell.execute_reply.started":"2022-08-20T10:29:35.180571Z","shell.execute_reply":"2022-08-20T10:29:35.188271Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"%%file src/host_floyd_warshall.cpp\n\n#include \"../include/host_floyd_warshall.hpp\"\n#include \"../include/adj_matrix_utils.hpp\"\n\n// ---------------------------------------------------------------------------\n// Matrix data structure version\n\nvoid host_matrix_floyd_warshall(int **matrix, int n) {\n    for(int k = 0; k < n; k++) {\n        for(int i = 0; i < n; i++) {\n            for(int j = 0; j < n; j++) {\n                int a = matrix[i][j];\n                int b = sum_if_not_infinite(matrix[i][k], matrix[k][j], INF);\n                matrix[i][j] = mmin(a, b);\n            }\n        }\n    }\n}\n\nvoid host_matrix_floyd_warshall_blocked(int **matrix, int n, int B) {\n\n    int num_rounds = n/B;\n\n    for(int t = 0; t < num_rounds; t++) { \n\n        //host_matrix_execute_round(int **matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        host_matrix_execute_round(matrix, n, t, t, t, B);\n\n        //phase 2 blocks left\n        for (int j = t-1; j >= 0; j--) {\n            host_matrix_execute_round(matrix, n, t, t, j, B);\n        }\n\n        //phase 2 blocks above\n        for (int i = t-1; i >= 0; i--) {\n            host_matrix_execute_round(matrix, n, t, i, t, B);\n        }\n\n        //phase 2 blocks below\n        for (int i = t+1; i < num_rounds; i++) {\n            host_matrix_execute_round(matrix, n, t, i, t, B);\n        }\n\n        //phase 2 blocks right\n        for (int j = t+1; j < num_rounds; j++) {\n            host_matrix_execute_round(matrix, n, t, t, j, B);\n        }\n        \n        //phase 2,3: remaining blocks\n        //phase 3 blocks above and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t-1; i >= 0; i--) {\n                host_matrix_execute_round(matrix, n, t, i, j, B);\n            }\n        }\n        //phase 3 blocks above and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t-1; i >= 0; i--) {\n                host_matrix_execute_round(matrix, n, t, i, j, B);\n            }\n        }\n        //phase 3 blocks below and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t+1; i < num_rounds; i++) {\n                host_matrix_execute_round(matrix, n, t, i, j, B);\n            }\n        }      \n        //phase 3 blocks below and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t+1; i < num_rounds; i++) {\n                host_matrix_execute_round(matrix, n, t, i, j, B);\n            }\n        }   \n        \n    }\n}\n\nvoid host_matrix_execute_round(int **matrix, int n, int t, int row, int col, int B) {\n\n    //foreach k: t*B <= t < t+B\n    int block_start = t * B;\n    int block_end = (t+1) * B;\n    int row_start = row * B;\n    int row_end = (row+1) * B;\n    int col_start = col * B;\n    int col_end = (col+1) * B;\n\n    for (int k = block_start; k < block_end; k++) {\n        //foreach i,j in the self-dependent block\n        for (int i = row_start; i < row_end; i++) {\n            for (int j = col_start; j < col_end; j++) {\n                int a = matrix[i][j];\n                int x1 = matrix[i][k];\n                int x2 =  matrix[k][j];\n                int b = sum_if_not_infinite(matrix[i][k], matrix[k][j], INF);\n                matrix[i][j] = mmin(a, b);\n                //print_matrix(matrix, n, n);\n            }\n        }\n    }\n}\n\n// ---------------------------------------------------------------------------\n// Array data structure version\n\nvoid host_array_floyd_warshall(int *matrix, int n) {\n    for(int k = 0; k < n; k++) {\n        for(int i = 0; i < n; i++) {\n            for(int j = 0; j < n; j++) {\n                int a = matrix[i*n + j];\n                int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF);\n                matrix[i*n + j] = mmin(a, b);\n            }\n        }\n    }\n}\n\nvoid host_array_floyd_warshall_blocked(int *matrix, int n, int B) {\n\n    int num_rounds = n/B;\n\n    for(int t = 0; t < num_rounds; t++) { \n\n        //host_matrix_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        host_array_execute_round(matrix, n, t, t, t, B);\n\n        //phase 2 blocks left\n        for (int j = t-1; j >= 0; j--) {\n            host_array_execute_round(matrix, n, t, t, j, B);\n        }\n\n        //phase 2 blocks above\n        for (int i = t-1; i >= 0; i--) {\n            host_array_execute_round(matrix, n, t, i, t, B);\n        }\n\n        //phase 2 blocks below\n        for (int i = t+1; i < num_rounds; i++) {\n            host_array_execute_round(matrix, n, t, i, t, B);\n        }\n\n        //phase 2 blocks right\n        for (int j = t+1; j < num_rounds; j++) {\n            host_array_execute_round(matrix, n, t, t, j, B);\n        }\n        \n        //phase 2,3: remaining blocks\n        //phase 3 blocks above and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t-1; i >= 0; i--) {\n                host_array_execute_round(matrix, n, t, i, j, B);\n            }\n        }\n        //phase 3 blocks above and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t-1; i >= 0; i--) {\n                host_array_execute_round(matrix, n, t, i, j, B);\n            }\n        }\n        //phase 3 blocks below and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t+1; i < num_rounds; i++) {\n                host_array_execute_round(matrix, n, t, i, j, B);\n            }\n        }      \n        //phase 3 blocks below and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t+1; i < num_rounds; i++) {\n                host_array_execute_round(matrix, n, t, i, j, B);\n            }\n        }   \n        \n    }\n}\n\nvoid host_array_execute_round(int *matrix, int n, int t, int row, int col, int B) {\n    //foreach k: t*B <= t < t+B\n    int block_start = t * B;\n    int block_end = (t+1) * B;\n    int row_start = row * B;\n    int row_end = (row+1) * B;\n    int col_start = col * B;\n    int col_end = (col+1) * B;\n    for (int k = block_start; k < block_end; k++) {\n        //foreach i,j in the self-dependent block\n        for (int i = row_start; i < row_end; i++) {\n            for (int j = col_start; j < col_end; j++) {\n                int a = matrix[i*n + j];\n                int x1 = matrix[i*n + k];\n                int x2 =  matrix[k*n + j];\n                int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF);\n                matrix[i*n + j] = mmin(a, b);\n                //print_arr_matrix(matrix, n, n);\n            }\n        }\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.191169Z","iopub.execute_input":"2022-08-20T10:29:35.191955Z","iopub.status.idle":"2022-08-20T10:29:35.203516Z","shell.execute_reply.started":"2022-08-20T10:29:35.191920Z","shell.execute_reply":"2022-08-20T10:29:35.201550Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"%%file src/performance_test.cu\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\n#include <cuda_profiler_api.h>\n\n#include \"../include/adj_matrix_utils.hpp\"\n#include \"../include/performance_test.cuh\"\n\nvoid do_nvprof_performance_test(void (*floyd_warshall_arr_algorithm)(int* matrix, int n, int B), int input_size, int blocking_factor, int number_of_tests, int seed) {\n\n    int* arr_matrix = allocate_arr_matrix(input_size, input_size);\n\n    for (int i=0; i<number_of_tests; i++) {\n\n        populate_arr_adj_matrix(arr_matrix, input_size, seed*(i+1), false);\n\n        cudaProfilerStart();\n        floyd_warshall_arr_algorithm(arr_matrix, input_size, blocking_factor);\n        cudaProfilerStop();\n\n        printf(\"Performed test number %d\\n\", i);\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.205079Z","iopub.execute_input":"2022-08-20T10:29:35.206547Z","iopub.status.idle":"2022-08-20T10:29:35.214732Z","shell.execute_reply.started":"2022-08-20T10:29:35.206511Z","shell.execute_reply":"2022-08-20T10:29:35.213793Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"%%file src/statistical_test.cpp\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <cassert>\n#include <cstring>\n\n#include \"../include/adj_matrix_utils.hpp\"\n#include \"../include/generate_n_b_couples.hpp\"\n#include \"../include/host_floyd_warshall.hpp\"\n#include \"../include/statistical_test.hpp\"\n\nbool exec_single_single_statistical_test(ExecSingleSizeTestParameters params) {\n\n    //just a rename of the same pointer\n    int *f_input = params.input_instance;\n\n    //define an input copy and allocate memory its memory\n    int *g_input = allocate_arr_matrix(params.input_size, params.input_size);\n\n    //make a copy of f_input to g_input\n    memcpy((void*) g_input, (void*) f_input, params.input_size * params.input_size * sizeof(int));\n    \n    //classic floyd_warshall on host, used to compare output\n    params.f(f_input, params.input_size, params.blocking_factor);\n\n    //function to test execution\n    params.g(g_input, params.input_size, params.blocking_factor);\n\n    //return true <==> foreach 0 <= i,j < n : input[i,j] = test[i,j]\n    return same_arr_matrixes(f_input, g_input, params.input_size, params.input_size, false);\n}\n\n\nint call_single_size_statistical_test(CallSingleSizeTestParameters params) {\n\n    /*\n    printf(\"Performing statistical test with:\\n\");\n    printf(\"\\t%d executions\\n\", n_tests);\n    if (use_always_seed==RANDOM_SEED) {\n        printf(\"\\tseed=RANDOM\\n\");\n    } else {\n        printf(\"\\tseed=%d\\n\", use_always_seed);\n    }\n\n    printf(\"\\tinput_size=%d\\n\\tblocking_factor=%d\\n\\n\", input_size, blocking_factor);\n    */\n\n    int n_wrong = 0;\n\n    //matrix initialization\n    int *input_instance = allocate_arr_matrix(params.input_size, params.input_size);\n\n    int i = 0;\n    for (; i < params.n_tests; i++)\n    {\n        // Progression status print\n        if((i > 0) && (i % (params.n_tests / params.print_progress_perc) == 0)) {\n            double perc = ((double) i) / ((double) params.n_tests);\n            printf(\"%d%%: %d of %d\\n\", (int) (perc*100), i, params.n_tests);\n        }\n        \n        // if necessary, generate (pseudo) random input instance\n        params.seed = (params.seed == RANDOM_SEED) ? clock() : params.seed;\n        \n        populate_arr_adj_matrix(input_instance, params.input_size, params.seed, false);\n\n        //define exec single test params\n        ExecSingleSizeTestParameters exec_params;\n        // most of parameters are copied as received:\n        exec_params.f               = params.f;\n        exec_params.g               = params.g;\n        exec_params.input_size      = params.input_size;\n        exec_params.blocking_factor = params.blocking_factor;\n        // input instance is allocated and populated here (based on seed value)\n        exec_params.input_instance  = input_instance; \n\n        // perform test\n        if (!exec_single_single_statistical_test(exec_params)) {\n\n            n_wrong++;\n\n            if (params.print_failed_tests) printf(\"%d/%d)\\tseed: %d --> ERROR!\\n\", i, params.n_tests, params.seed);\n            \n            if (params.stop_current_if_fail) break;\n        }\n    }\n\n    free(input_instance);\n\n    printf(\"Test ended. Performed %d/%d tests and got %d/%d errors\\n\", i, params.n_tests, n_wrong, params.n_tests);\n\n    return n_wrong;\n}\n\nint multi_size_statistical_test(MultiSizeTestParameters params) {\n\n    assert(params.end_input_size >= params.start_input_size);\n    // stop_all_if_fail ==> stop_current_if_fail\n    params.stop_current_if_fail = params.stop_current_if_fail || params.stop_all_if_fail;\n    \n    int seed = time(NULL);\n    srand(seed);\n    \n    // calculate default values\n    double rand_to_multiply = OBTAIN_VAL_TO_MULTIPLY(rand());\n    int rand_to_sum = OBTAIN_VAL_TO_SUM(rand());\n    // if parameter is random then use calculated values, else use parameter\n    params.to_multiply = (params.to_multiply == RANDOM_CONSTANT) ? rand_to_multiply : params.to_multiply;\n    params.to_sum =      (params.to_sum      == RANDOM_CONSTANT) ? rand_to_sum      : params.to_sum;\n    // in case is used the parameter value, check if it is non-negative\n    assert(params.to_multiply >= 0);\n    assert(params.to_sum      >= 0);\n\n    printf(\"Performing Multi-size statistical test:\\n\");\n    printf(\"- Input sizes between %d and %d, increase is linear, using %f as costant multiplier\\n\", params.start_input_size, params.end_input_size, params.to_multiply);\n    printf(\"- Blocking factor are generated randomly between [1, n/2] U {n}\\n\");\n    printf(\"- Number of executions for each couple (n,B) used: %d\\n\\n\", params.n_tests_per_round);\n\n    int n_err_tot = 0;\n\n    std::vector<std::pair<int, int>> list_of_all_n_b;\n    list_of_all_n_b = generate_list_of_all_n_b(params.start_input_size, params.end_input_size, 5, params.to_multiply, params.to_sum, params.min_blocking_factor, 50, seed);\n\n    for (int i = 0; i < list_of_all_n_b.size(); i++) {\n\n        int n = list_of_all_n_b[i].first;\n        int B = list_of_all_n_b[i].second;\n\n        //printf(\"n: %d, B: %d\\n\", n, B);\n\n        //define exec single test params\n        CallSingleSizeTestParameters single_test_params;\n        // most of parameters are copied as received:\n        single_test_params.f                    = params.f;\n        single_test_params.g                    = params.g;\n        single_test_params.seed                 = params.seed;\n        single_test_params.n_tests              = params.n_tests_per_round;\n        single_test_params.print_progress_perc  = params.print_progress_perc;\n        single_test_params.print_failed_tests   = params.print_failed_tests;\n        single_test_params.stop_current_if_fail = params.stop_current_if_fail;\n        // the couple (n,B) is calculated here\n        single_test_params.input_size      = n;\n        single_test_params.blocking_factor = B;\n\n        //execute test\n        int n_err = call_single_size_statistical_test(single_test_params);\n        \n        // count errors\n        n_err_tot += n_err;\n        if (n_err > 0 && params.stop_all_if_fail) {\n            return n_err_tot;\n        }\n        \n        printf(\"Cumulative errors at size=%d, blocking_factor=%d: %d (%d new ones)\\n\\n\", n, B, n_err_tot, n_err);\n        \n    }\n\n    return n_err_tot;\n}\n\nvoid print_multi_size_test_parameters(MultiSizeTestParameters params) {\n    printf(\"MultiSizeTestParameters:\\n\");\n    printf(\"- pointer to test func:\\t%p\\n\", &params.f);\n    printf(\"- pointer to comp func:\\t%p\\n\", &params.g);\n    printf(\"- start input size:\\t%d\\n\", params.start_input_size);\n    printf(\"- end input size:\\t%d\\n\", params.end_input_size);\n    printf(\"- costant multiplier:\\t\");\n    if (params.seed == RANDOM_CONSTANT) printf(\"RANDOM\\n\");\n    else                                printf(\"%f\\n\", params.to_multiply);\n    printf(\"- seed:\\t\\t\\t\");\n    if (params.seed == RANDOM_SEED)     printf(\"RANDOM\\n\");\n    else                                printf(\"%d\\n\", params.seed);\n    printf(\"- n tests per round:\\t%d\\n\", params.n_tests_per_round);\n    printf(\"- print progress perc:\\t%d%%\\n\", (100 / params.print_progress_perc));\n    printf(\"- stop current if fail:\\t%s\\n\", bool_to_string(params.stop_current_if_fail));\n    printf(\"- stop all if fail:\\t%s\\n\", bool_to_string(params.stop_all_if_fail));\n    printf(\"- print failed tests:\\t%s\\n\", bool_to_string(params.print_failed_tests));\n    printf(\"- blocking factor:\\tRANDOM\\n\");\n    printf(\"\\n\");\n}\n\nvoid print_call_single_size_statistical_test_parameters(CallSingleSizeTestParameters params) {\n    printf(\"CallSingleSizeTestParameters:\\n\");\n    printf(\"- pointer to test func:\\t%p\\n\", &params.f);\n    printf(\"- pointer to comp func:\\t%p\\n\", &params.g);\n    printf(\"- input size:\\t%d\\n\", params.input_size);\n    printf(\"- blocking factor:\\t%d\\n\", params.blocking_factor);\n    printf(\"- seed:\\t\\t\\t\");\n    if (params.seed == RANDOM_SEED)     printf(\"RANDOM\\n\");\n    else                                printf(\"%d\\n\", params.seed);\n    printf(\"- n tests:\\t\\t%d\\n\", params.n_tests);\n    printf(\"- print progress perc:\\t%d%%\\n\", (100 / params.print_progress_perc));\n    printf(\"- stop current if fail:\\t%s\\n\", bool_to_string(params.stop_current_if_fail));\n    printf(\"- print failed tests:\\t%s\\n\", bool_to_string(params.print_failed_tests));\n    printf(\"\\n\");\n}\n\nvoid print_exec_single_size_statistical_test_parameters(ExecSingleSizeTestParameters params) {\n    printf(\"ExecSingleSizeTestParameters:\\n\");\n    printf(\"- pointer to test func:\\t%p\\n\", &params.f);\n    printf(\"- pointer to comp func:\\t%p\\n\", &params.g);\n    printf(\"- input size:\\t%d\\n\", params.input_size);\n    printf(\"- blocking factor:\\t%d\\n\", params.blocking_factor);\n    printf(\"- pointer to input data:\\t%p\\n\", &params.input_instance);\n    printf(\"\\n\");\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.216570Z","iopub.execute_input":"2022-08-20T10:29:35.216934Z","iopub.status.idle":"2022-08-20T10:29:35.229471Z","shell.execute_reply.started":"2022-08-20T10:29:35.216867Z","shell.execute_reply":"2022-08-20T10:29:35.228342Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# END SRC REGION\n# ----------------------------------------------------------------------------------------------------------------------------------------\n# START MAIN REGION","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.231377Z","iopub.execute_input":"2022-08-20T10:29:35.232004Z","iopub.status.idle":"2022-08-20T10:29:35.238989Z","shell.execute_reply.started":"2022-08-20T10:29:35.231968Z","shell.execute_reply":"2022-08-20T10:29:35.238131Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_0_ERROR.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_0(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_0(int *matrix, int n, int t, int row, int col, int B);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_0);\n\n}\n\n__global__ void execute_round_device_v_1_0(int *matrix, int n, int t, int row, int col, int B) {\n\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\n    int i = tid/n;  // row\n    int j = tid%n;  // col\n\n    //foreach k: t*B <= t < t+B\n    for (int k = t * B; k < (t+1) * B; k++) {\n\n        int a, b;\n        bool run_this = ((i >= row*B) && (i < (row+1)*B) && (j >= col*B) && (j < (col+1)*B));\n\n        // check if thread correspond to one of the cells in current block\n        if (run_this) {\n\n            // WARNING: do NOT put the macro directly into \n            a = matrix[i*n + j];\n            b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n        }\n\n        __syncthreads();\n\n\n        if (run_this) {\n            matrix[i*n + j] = mmin(a, b);\n        }\n        \n        __syncthreads();\n\n    }\n}\n\n\nvoid floyd_warshall_blocked_device_v_1_0(int *matrix, int n, int B) {\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n    \n    int num_rounds = n/B;\n\n    int num_blocks = num_rounds*num_rounds;\n    int thread_per_block = B*B; \n    \n\n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, t, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        //phase 2 blocks left\n        for (int j = t-1; j >= 0; j--) {\n            execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, t, j, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks above\n        for (int i = t-1; i >= 0; i--) {\n            execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, i, t, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks below\n        for (int i = t+1; i < num_rounds; i++) {\n            execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, i, t, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks right\n        for (int j = t+1; j < num_rounds; j++) {\n            execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, t, j, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n        \n        //phase 3 blocks above and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t-1; i >= 0; i--) {\n                execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n        //phase 3 blocks above and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t-1; i >= 0; i--) {\n                execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n        //phase 3 blocks below and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t+1; i < num_rounds; i++) {\n                execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }      \n        //phase 3 blocks below and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t+1; i < num_rounds; i++) {\n                execute_round_device_v_1_0<<<num_blocks, thread_per_block>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n\n        // HANDLE_ERROR(cudaDeviceSynchronize());   \n    }\n\n    HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.241445Z","iopub.execute_input":"2022-08-20T10:29:35.242231Z","iopub.status.idle":"2022-08-20T10:29:35.252658Z","shell.execute_reply.started":"2022-08-20T10:29:35.242196Z","shell.execute_reply":"2022-08-20T10:29:35.251577Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_1_pitch.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_1_pitch(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_1_pitch(int *matrix, int n, int t, int row, int col, int B, size_t pitch);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_1_pitch);\n\n}\n\n\nvoid floyd_warshall_blocked_device_v_1_1_pitch(int *matrix, int n, int B) {\n    \n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    size_t pitch;                          //size in bytes of memory allocated to guarantee alignment\n    size_t width = n * sizeof(int);\n    size_t height = n;\n\n    //cudaMallocPitch(&devPtr, &devPitch, N_cols * sizeof(type), N_rows);\n\n    HANDLE_ERROR(cudaMallocPitch( (void**) &dev_rand_matrix, &pitch, width, height));\n    //HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n * n * sizeof(int), cudaMemcpyHostToDevice));\n    HANDLE_ERROR(cudaMemcpy2D(dev_rand_matrix, pitch, matrix, width, width, height, cudaMemcpyHostToDevice));\n\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        // printf(\"start self dependent, t:%d, row:%d, col:%d\\n\",t,t,t);\n        execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, t, t, B, pitch);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        //phase 2 blocks left\n        for (int j = t-1; j >= 0; j--) {\n            // printf(\"start phase 2 blocks left, t:%d, row:%d, col:%d\\n\",t,t,j);\n            execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, t, j, B, pitch);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks above\n        for (int i = t-1; i >= 0; i--) {\n            // printf(\"start phase 2 blocks above, t:%d, row:%d, col:%d\\n\",t,i,t);\n            execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, t, B, pitch);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks below\n        for (int i = t+1; i < num_rounds; i++) {\n            // printf(\"start phase 2 blocks below, t:%d, row:%d, col:%d\\n\",t,i,t);\n            execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, t, B, pitch);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks right\n        for (int j = t+1; j < num_rounds; j++) {\n            // printf(\"start phase 2 blocks right, t:%d, row:%d, col:%d\\n\",t,t,j);\n            execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, t, j, B, pitch);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n        \n        //phase 3 blocks above and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t-1; i >= 0; i--) {\n                // printf(\"start phase 3 blocks above and right, t:%d, row:%d, col:%d\\n\",t,i,j);\n                execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B, pitch);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n        //phase 3 blocks above and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t-1; i >= 0; i--) {\n                // printf(\"start phase 3 blocks above and left, t:%d, row:%d, col:%d\\n\",t,i,j);\n                execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B, pitch);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n        //phase 3 blocks below and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t+1; i < num_rounds; i++) {\n                // printf(\"start phase 3 blocks below and left, t:%d, row:%d, col:%d\\n\",t,i,j);\n                execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B, pitch);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }      \n        //phase 3 blocks below and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t+1; i < num_rounds; i++) {\n                // printf(\"start phase 3 blocks below and right, t:%d, row:%d, col:%d\\n\",t,i,j);\n                execute_round_device_v_1_1_pitch<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B, pitch);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n\n        HANDLE_ERROR(cudaDeviceSynchronize());  \n    }\n\n    // HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaMemcpy2D(matrix, width, dev_rand_matrix, pitch, width, height, cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n__global__ void execute_round_device_v_1_1_pitch(int *matrix, int n, int t, int row, int col, int B, size_t pitch) {\n\n    int tid_x = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid_y = threadIdx.y + blockIdx.y * blockDim.y;\n    \n    int i = tid_x + row * B;  // row\n    int j = tid_y + col * B;  // col\n    \n    int *cell_i_j = pitched_pointer(matrix, i, j, pitch); //(int *)((char*) matrix + i * pitch) + j;\n    //int cell_i_j_bef = *cell_i_j;\n\n    /*\n    printf(\n        \"tid_x:%d, tid_y:%d, i:%d, j:%d, threadIdx.x:%d, blockIdx.x:%d, blockDim.x:%d, threadIdx.y:%d, blockIdx.y:%d, blockDim.y:%d\\n\",\n        tid_x, tid_y, i, j, threadIdx.x, blockIdx.x, blockDim.x, threadIdx.y, blockIdx.y, blockDim.y\n    );\n    */\n\n    //foreach k: t*B <= t < t+B\n    for (int k = t * B; k < (t+1) * B; k++) {\n\n        int* cell_k_j = pitched_pointer(matrix, k, j, pitch); //(int *)((char*) matrix + k * pitch) + j;\n        int* cell_i_k = pitched_pointer(matrix, i, k, pitch); //(int *)((char*) matrix + i * pitch) + k;\n\n        int using_k_path = sum_if_not_infinite(*cell_i_k, *cell_k_j, INF); \n\n        if (using_k_path < *cell_i_j) {\n            *cell_i_j = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d, max_k:%d, ik:%02d, kj:%02d, ij_bef:%02d, ij_aft:%02d\\n\", i, j, k, (t+1)*B, (mmin(*cell_i_k, 99)), (mmin(*cell_k_j, 99)), (mmin(cell_i_j_bef, 99)), (mmin(*cell_i_j, 99)));\n        // if (tid_x==0 && tid_y==0) printf(\"i:%d, j:%d, k:%d, max_k:%d\\n\", i, j, k, (t+1)*B);      \n        \n        __syncthreads();\n\n\n        /*\n        if((i % 2 == 0) && (j % 2 == 0)) {\n            printf(\"k:%d\\n\",k);\n            print_matrix_device(matrix, n, n, pitch);\n            printf(\"\\n\");\n        }\n        */\n\n    }\n    \n}\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.254299Z","iopub.execute_input":"2022-08-20T10:29:35.254736Z","iopub.status.idle":"2022-08-20T10:29:35.268544Z","shell.execute_reply.started":"2022-08-20T10:29:35.254666Z","shell.execute_reply":"2022-08-20T10:29:35.267609Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_1.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_1(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_1(int *matrix, int n, int t, int row, int col, int B);\n\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_1);\n\n}\n\n__global__ void execute_round_device_v_1_1(int *matrix, int n, int t, int row, int col, int B) {\n\n    int tid_x = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid_y = threadIdx.y + blockIdx.y * blockDim.y;\n\n    int i = tid_x + row * B;  // row\n    int j = tid_y + col * B;  // col\n    \n    /*\n    printf(\n        \"tid_x:%d, tid_y:%d, i:%d, j:%d, threadIdx.x:%d, blockIdx.x:%d, blockDim.x:%d, threadIdx.y:%d, blockIdx.y:%d, blockDim.y:%d\\n\",\n        tid_x, tid_y, i, j, threadIdx.x, blockIdx.x, blockDim.x, threadIdx.y, blockIdx.y, blockDim.y\n    );\n    */\n\n    //foreach k: t*B <= t < t+B\n    for (int k = t * B; k < (t+1) * B; k++) {\n\n        int a, b;\n        bool run_this = true; // i>=row * B && i<(row+1) * B && j>=col * B && j<(col+1) * B;\n\n        // check if thread correspond to one of the cells in current block\n        if (run_this) {\n\n            // WARNING: do NOT put the macro directly into \n            a = matrix[i*n + j];\n            b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n        }\n\n        // __syncthreads();\n\n        if (b < a) {\n            matrix[i*n + j] = b;\n        }\n        \n        __syncthreads();\n\n        /*\n        if((i % 2 == 0) && (j % 2 == 0)) {\n            printf(\"k:%d\\n\",k);\n            //print_matrix_device(matrix, n, n);\n            printf(\"\\n\");\n        }\n        */\n    }\n}\n\nvoid floyd_warshall_blocked_device_v_1_1(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, t, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        //phase 2 blocks left\n        for (int j = t-1; j >= 0; j--) {\n            execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, t, j, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks above\n        for (int i = t-1; i >= 0; i--) {\n            execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, t, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks below\n        for (int i = t+1; i < num_rounds; i++) {\n            execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, t, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        //phase 2 blocks right\n        for (int j = t+1; j < num_rounds; j++) {\n            execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, t, j, B);\n            // HANDLE_ERROR(cudaDeviceSynchronize());  \n        }\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n        \n        //phase 3 blocks above and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t-1; i >= 0; i--) {\n                execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n        //phase 3 blocks above and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t-1; i >= 0; i--) {\n                execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n        //phase 3 blocks below and left\n        for (int j = t-1; j >= 0; j--) {\n            for (int i = t+1; i < num_rounds; i++) {\n                execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }      \n        //phase 3 blocks below and right\n        for (int j = t+1; j < num_rounds; j++) {\n            for (int i = t+1; i < num_rounds; i++) {\n                execute_round_device_v_1_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, i, j, B);\n                // HANDLE_ERROR(cudaDeviceSynchronize());  \n            }\n        }\n\n        HANDLE_ERROR(cudaDeviceSynchronize());   \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.275608Z","iopub.execute_input":"2022-08-20T10:29:35.276032Z","iopub.status.idle":"2022-08-20T10:29:35.284855Z","shell.execute_reply.started":"2022-08-20T10:29:35.276006Z","shell.execute_reply":"2022-08-20T10:29:35.283923Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_2.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_2(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_2_phase_1(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_2_phase_2(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_2_phase_3(int *matrix, int n, int t, int B);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_2);\n\n}\n\n\nvoid floyd_warshall_blocked_device_v_1_2(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_1_2_phase_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        // Phase 2/3 thread matrix is made by n*n threads, divided in num_rounds*num_rounds blocks\n        dim3 num_blocks_phase_2_3(num_rounds, num_rounds);  \n\n        execute_round_device_v_1_2_phase_2<<<num_blocks_phase_2_3, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        execute_round_device_v_1_2_phase_3<<<num_blocks_phase_2_3, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n__global__ void execute_round_device_v_1_2_phase_1(int *matrix, int n, int t, int B) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    int tid_x = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid_y = threadIdx.y + blockIdx.y * blockDim.y;\n\n    int i = tid_x + t * B;  // row\n    int j = tid_y + t * B;  // col\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (b < matrix[i*n + j]) {\n            matrix[i*n + j] = b;\n        }\n        \n        __syncthreads();\n    }\n}\n\n__global__ void execute_round_device_v_1_2_phase_2(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix \n    // (\"-\" and \".\" blocks are just kept inactive using IF statement)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        if (\n            /* row index is contained in s.d. block and column index is outside */\n            ( BLOCK_START(t,B)<=i<BLOCK_END(t,B) && (j<BLOCK_START(t,B) || j>=BLOCK_END(t,B)) )   ||  \n\n            /* column index is contained in s.d. block and row index is outside */\n            ( BLOCK_START(t,B)<=j<BLOCK_END(t,B) && (i<BLOCK_START(t,B) || i>=BLOCK_END(t,B)) ) \n            ) {\n\n            int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n            if (b < matrix[i*n + j]) {\n                matrix[i*n + j] = b;\n            }\n        }\n\n        __syncthreads();\n    }\n}\n\n__global__ void execute_round_device_v_1_2_phase_3(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix \n    // (\"-\" blocks are just kept inactive using IF statement)\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        if (\n            /* above and right or left */\n            ( i>=BLOCK_END(t,B) && (j<BLOCK_START(t,B) || j>=BLOCK_END(t,B)) )   ||  \n\n            /* under and right or left */\n            ( i<BLOCK_START(t,B) && (j<BLOCK_START(t,B) || j>=BLOCK_END(t,B)) ) \n            ) {\n\n            int using_k_path = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n            if (using_k_path < matrix[i*n + j]) {\n                matrix[i*n + j] = using_k_path;\n            }\n        }\n\n        __syncthreads();\n    }\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.286734Z","iopub.execute_input":"2022-08-20T10:29:35.287743Z","iopub.status.idle":"2022-08-20T10:29:35.299915Z","shell.execute_reply.started":"2022-08-20T10:29:35.287703Z","shell.execute_reply":"2022-08-20T10:29:35.298445Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_3_pitch.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_3_pitch(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_2_phase_1(int *matrix, int n, int t, int B, size_t pitch);\n__global__ void execute_round_device_v_1_3_phase_2(int *matrix, int n, int t, int B, size_t pitch);\n__global__ void execute_round_device_v_1_3_phase_3(int *matrix, int n, int t, int B, size_t pitch);\n\nint main(int argc, char *argv[]) {\n\n    //do_nvprof_performance_test(&floyd_warshall_blocked_device_v_1_3_pitch, 50, 10, 1, time(NULL));\n    int n = 10;\n    int b = 2;\n    int* matrix = allocate_arr_matrix(n, n);\n    populate_arr_adj_matrix(matrix, n, time(NULL), true);\n    floyd_warshall_blocked_device_v_1_3_pitch(matrix, n, b);\n    return 0;\n\n    //return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_3_pitch);\n\n}\n\nvoid floyd_warshall_blocked_device_v_1_3_pitch(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    size_t pitch;                          //size in bytes of memory allocated to guarantee alignment\n    size_t width = n * sizeof(int);\n    size_t height = n;\n\n    //cudaMallocPitch(&devPtr, &devPitch, N_cols * sizeof(type), N_rows);\n\n    HANDLE_ERROR(cudaMallocPitch( (void**) &dev_rand_matrix, &pitch, width, height));\n    //HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n * n * sizeof(int), cudaMemcpyHostToDevice));\n    HANDLE_ERROR(cudaMemcpy2D(dev_rand_matrix, pitch, matrix, width, width, height, cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        printf(\"round %d of %d\\n\", t, num_rounds);\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        printf(\"1 start\\n\");\n\n        execute_round_device_v_1_2_phase_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B, pitch);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n        \n        printf(\"1 end\\n\");\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n\n        dim3 num_blocks_phase_2(2, num_rounds-1);  \n\n        printf(\"2 start\\n\");\n\n        execute_round_device_v_1_3_phase_2<<<num_blocks_phase_2, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B, pitch);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n        \n        printf(\"2 end\\n\");\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n\n        printf(\"3 start\\n\");\n\n        execute_round_device_v_1_3_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B, pitch);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n        \n        printf(\"3 end\\n\");\n    }\n\n    // HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaMemcpy2D(matrix, width, dev_rand_matrix, pitch, width, height, cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n\n__global__ void execute_round_device_v_1_2_phase_1(int *matrix, int n, int t, int B, size_t pitch) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    int tid_x = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid_y = threadIdx.y + blockIdx.y * blockDim.y;\n\n    int i = tid_x + t * B;  // row\n    int j = tid_y + t * B;  // col\n\n    int *cell_i_j = pitched_pointer(matrix, i, j, pitch);\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int* cell_k_j = pitched_pointer(matrix, k, j, pitch); //(int *)((char*) matrix + k * pitch) + j;\n        int* cell_i_k = pitched_pointer(matrix, i, k, pitch); //(int *)((char*) matrix + i * pitch) + k;\n    \n        int using_k_path = sum_if_not_infinite(*cell_i_k, *cell_k_j, INF); \n\n        if (using_k_path < *cell_i_j) {\n            *cell_i_j = using_k_path;\n        }\n        \n        __syncthreads();\n    }\n}\n\n__global__ void execute_round_device_v_1_3_phase_2(int *matrix, int n, int t, int B, size_t pitch) {\n\n    // Launched blocks and correspondent position in the matrix\n    //  -   blockIdx.x says if I am iterating row or cols, \n    //  -   blockIdx.y says something about which row or col)\n    //  -   threadIdx.x and threadIdx.y are relative position of cell in block\n\n    //  L1  L2  L3  R1  R2\n    //  U1  U2  U3  D1  D2\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    int i, j;\n\n    if (blockIdx.x == 0) {  \n\n        // it's a row ...\n        i = BLOCK_START(t, B) + threadIdx.x;\n\n        if (blockIdx.y < t) {\n\n            // ... and it's the left one\n            j = BLOCK_START(blockIdx.y, B) + threadIdx.y;\n\n        } else {\n            \n            // ... and it's the right one\n            j = BLOCK_START(blockIdx.y, B) + B + threadIdx.y;\n        }\n    } else {\n\n        // it's a column ...\n        j = BLOCK_START(t, B) + threadIdx.y;\n\n        if (blockIdx.y < t) {\n\n            // ... and it's the up one\n            i = BLOCK_START(blockIdx.y, B) + threadIdx.x;\n\n        } else {\n\n            // ... and it's the down one\n            i = BLOCK_START(blockIdx.y, B) + B + threadIdx.x;\n        }\n    }\n\n    int *cell_i_j = pitched_pointer(matrix, i, j, pitch); \n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        if (\n            /* row index is contained in s.d. block and column index is outside */\n            ( BLOCK_START(t,B)<=i<BLOCK_END(t,B) && (j<BLOCK_START(t,B) || j>=BLOCK_END(t,B)) )   ||  \n\n            /* column index is contained in s.d. block and row index is outside */\n            ( BLOCK_START(t,B)<=j<BLOCK_END(t,B) && (i<BLOCK_START(t,B) || i>=BLOCK_END(t,B)) ) \n            ) {\n\n            int* cell_k_j = pitched_pointer(matrix, k, j, pitch); //(int *)((char*) matrix + k * pitch) + j;\n            int* cell_i_k = pitched_pointer(matrix, i, k, pitch); //(int *)((char*) matrix + i * pitch) + k;\n    \n            int using_k_path = sum_if_not_infinite(*cell_i_k, *cell_k_j, INF); \n    \n            if (using_k_path < *cell_i_j) {\n                *cell_i_j = using_k_path;\n            }\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n\n    }\n}\n\n\n__global__ void execute_round_device_v_1_3_phase_3(int *matrix, int n, int t, int B, size_t pitch) {\n\n    // Launched blocks and correspondent position in the matrix\n\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  DL  DL  DL  DR  DR\n    //  DL  DL  DL  DR  DR\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n           \n    // if a thread is under t, add B as row offset to get right position in matrix\n    if (blockIdx.x >= t)    i += B; \n\n    // if a thread is ar right of t, add B as col offset to get right position in matrix\n    if (blockIdx.y >= t)    j += B;\n\n    int *cell_i_j = pitched_pointer(matrix, i, j, pitch); \n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int* cell_k_j = pitched_pointer(matrix, k, j, pitch); //(int *)((char*) matrix + k * pitch) + j;\n        int* cell_i_k = pitched_pointer(matrix, i, k, pitch); //(int *)((char*) matrix + i * pitch) + k;\n\n        int using_k_path = sum_if_not_infinite(*cell_i_k, *cell_k_j, INF); \n\n        if (using_k_path < *cell_i_j) {\n            *cell_i_j = using_k_path;\n        }\n\n        __syncthreads();\n    }\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T11:00:11.924218Z","iopub.execute_input":"2022-08-20T11:00:11.925147Z","iopub.status.idle":"2022-08-20T11:00:11.938143Z","shell.execute_reply.started":"2022-08-20T11:00:11.925097Z","shell.execute_reply":"2022-08-20T11:00:11.936599Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_3.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_3(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_2_phase_1(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_3_phase_2(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_3_phase_3(int *matrix, int n, int t, int B);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_3);\n\n}\n\nvoid floyd_warshall_blocked_device_v_1_3(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_1_2_phase_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        dim3 num_blocks_phase_2(2, num_rounds-1);  \n\n        execute_round_device_v_1_3_phase_2<<<num_blocks_phase_2, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n\n        execute_round_device_v_1_3_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n\n__global__ void execute_round_device_v_1_2_phase_1(int *matrix, int n, int t, int B) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    int tid_x = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid_y = threadIdx.y + blockIdx.y * blockDim.y;\n\n    int i = tid_x + t * B;  // row\n    int j = tid_y + t * B;  // col\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (b < matrix[i*n + j]) {\n            matrix[i*n + j] = b;\n        }\n        \n        __syncthreads();\n    }\n}\n\n__global__ void execute_round_device_v_1_3_phase_2(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix\n    //  -   blockIdx.x says if I am iterating row or cols, \n    //  -   blockIdx.y says something about which row or col)\n    //  -   threadIdx.x and threadIdx.y are relative position of cell in block\n\n    //  L1  L2  L3  R1  R2\n    //  U1  U2  U3  D1  D2\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    int i, j;\n\n    if (blockIdx.x == 0) {  \n\n        // it's a row ...\n        i = BLOCK_START(t, B) + threadIdx.x;\n\n        if (blockIdx.y < t) {\n\n            // ... and it's the left one\n            j = BLOCK_START(blockIdx.y, B) + threadIdx.y;\n\n        } else {\n            \n            // ... and it's the right one\n            j = BLOCK_START(blockIdx.y, B) + B + threadIdx.y;\n        }\n    } else {\n\n        // it's a column ...\n        j = BLOCK_START(t, B) + threadIdx.y;\n\n        if (blockIdx.y < t) {\n\n            // ... and it's the up one\n            i = BLOCK_START(blockIdx.y, B) + threadIdx.x;\n\n        } else {\n\n            // ... and it's the down one\n            i = BLOCK_START(blockIdx.y, B) + B + threadIdx.x;\n        }\n    }\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        if (\n            /* row index is contained in s.d. block and column index is outside */\n            ( BLOCK_START(t,B)<=i<BLOCK_END(t,B) && (j<BLOCK_START(t,B) || j>=BLOCK_END(t,B)) )   ||  \n\n            /* column index is contained in s.d. block and row index is outside */\n            ( BLOCK_START(t,B)<=j<BLOCK_END(t,B) && (i<BLOCK_START(t,B) || i>=BLOCK_END(t,B)) ) \n            ) {\n\n            int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n            if (b < matrix[i*n + j]) {\n                matrix[i*n + j] = b;\n            }\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n\n    }\n}\n\n\n__global__ void execute_round_device_v_1_3_phase_3(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix\n\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  DL  DL  DL  DR  DR\n    //  DL  DL  DL  DR  DR\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n           \n    // if a thread is under t, add B as row offset to get right position in matrix\n    if (blockIdx.x >= t)    i += B; \n\n    // if a thread is ar right of t, add B as col offset to get right position in matrix\n    if (blockIdx.y >= t)    j += B;\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int using_k_path = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (using_k_path < matrix[i*n + j]) {\n            matrix[i*n + j] = using_k_path;\n        }\n\n        __syncthreads();\n    }\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.316893Z","iopub.execute_input":"2022-08-20T10:29:35.317465Z","iopub.status.idle":"2022-08-20T10:29:35.330559Z","shell.execute_reply.started":"2022-08-20T10:29:35.317360Z","shell.execute_reply":"2022-08-20T10:29:35.329496Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_1_4.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_1_4(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_1_4_phase_1(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_4_phase_2_row(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_4_phase_2_col(int *matrix, int n, int t, int B);\n__global__ void execute_round_device_v_1_4_phase_3(int *matrix, int n, int t, int B);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_1_4);\n\n}\n\nvoid floyd_warshall_blocked_device_v_1_4(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_1_4_phase_1<<<num_blocks_phase_1, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        dim3 num_blocks_phase_2(1, num_rounds-1);  \n\n        execute_round_device_v_1_4_phase_2_row<<<num_blocks_phase_2, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        execute_round_device_v_1_4_phase_2_col<<<num_blocks_phase_2, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n\n        execute_round_device_v_1_4_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1>>>(dev_rand_matrix, n, t, B);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n\n__global__ void execute_round_device_v_1_4_phase_1(int *matrix, int n, int t, int B) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    int tid_x = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid_y = threadIdx.y + blockIdx.y * blockDim.y;\n\n    int i = tid_x + t * B;  // row\n    int j = tid_y + t * B;  // col\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (b < matrix[i*n + j]) {\n            matrix[i*n + j] = b;\n        }\n        \n        __syncthreads();\n    }\n}\n\n__global__ void execute_round_device_v_1_4_phase_2_row(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix\n    //  -   blockIdx.x says if I am iterating row or cols, \n    //  -   blockIdx.y says something about which row or col)\n    //  -   threadIdx.x and threadIdx.y are relative position of cell in block\n\n    //  L1  L2  L3  R1  R2\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    int i, j;\n\n    // it's a row ...\n    i = BLOCK_START(t, B) + threadIdx.x;\n\n    if (blockIdx.y < t) {\n\n        // ... and it's the left one\n        j = BLOCK_START(blockIdx.y, B) + threadIdx.y;\n\n    } else {\n        \n        // ... and it's the right one\n        j = BLOCK_START(blockIdx.y, B) + B + threadIdx.y;\n    }\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (b < matrix[i*n + j]) {\n            matrix[i*n + j] = b;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n\n    }\n}\n\n__global__ void execute_round_device_v_1_4_phase_2_col(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix\n    //  -   blockIdx.x says if I am iterating row or cols, \n    //  -   blockIdx.y says something about which row or col)\n    //  -   threadIdx.x and threadIdx.y are relative position of cell in block\n\n    //  U1  U2  U3  D1  D2\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    int i, j;\n\n    // it's a column ...\n    j = BLOCK_START(t, B) + threadIdx.y;\n\n    if (blockIdx.y < t) {\n\n        // ... and it's the up one\n        i = BLOCK_START(blockIdx.y, B) + threadIdx.x;\n\n    } else {\n\n        // ... and it's the down one\n        i = BLOCK_START(blockIdx.y, B) + B + threadIdx.x;\n    }\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int b = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (b < matrix[i*n + j]) {\n            matrix[i*n + j] = b;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n}\n\n\n__global__ void execute_round_device_v_1_4_phase_3(int *matrix, int n, int t, int B) {\n\n    // Launched blocks and correspondent position in the matrix\n\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  DL  DL  DL  DR  DR\n    //  DL  DL  DL  DR  DR\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n           \n    // if a thread is under t, add B as row offset to get right position in matrix\n    if (blockIdx.x >= t)    i += B; \n\n    // if a thread is ar right of t, add B as col offset to get right position in matrix\n    if (blockIdx.y >= t)    j += B;\n\n    //foreach k: t*B <= t < t+B\n    for (int k = BLOCK_START(t,B); k < BLOCK_END(t,B); k++) {\n\n        int using_k_path = sum_if_not_infinite(matrix[i*n + k], matrix[k*n + j], INF); \n\n        if (using_k_path < matrix[i*n + j]) {\n            matrix[i*n + j] = using_k_path;\n        }\n\n        __syncthreads();\n    }\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.332128Z","iopub.execute_input":"2022-08-20T10:29:35.333326Z","iopub.status.idle":"2022-08-20T10:29:35.345820Z","shell.execute_reply.started":"2022-08-20T10:29:35.333291Z","shell.execute_reply":"2022-08-20T10:29:35.344557Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_2_0.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_2_0(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_2_0_phase_1(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_0_phase_2_row(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_0_phase_2_col(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_0_phase_3(int *matrix, int n, int t);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_2_0);\n\n}\n\nvoid floyd_warshall_blocked_device_v_2_0(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_2_0_phase_1<<<num_blocks_phase_1, threads_per_block_phase_1, B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        // dim3 num_blocks_phase_2(1, num_rounds-1);  \n\n        execute_round_device_v_2_0_phase_2_row<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        execute_round_device_v_2_0_phase_2_col<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n\n        execute_round_device_v_2_0_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n\n__global__ void execute_round_device_v_2_0_phase_1(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    extern __shared__ int block_t_t_shared[];\n\n    int i = threadIdx.x + t * blockDim.x;  // row abs index\n    int j = threadIdx.y + t * blockDim.x;  // col abs index\n\n    block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[i*n + j];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[threadIdx.x*blockDim.x + k], \n            block_t_t_shared[k*blockDim.x + threadIdx.y], \n            INF\n        ); \n\n        if (using_k_path < block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y]) {\n            block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = using_k_path;\n        }\n        \n        __syncthreads();\n    }\n\n    matrix[i*n + j] = block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y];\n}\n\n__global__ void execute_round_device_v_2_0_phase_2_row(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  L1  L2  L3  R1  R2      \n    //  (trasposed)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    extern __shared__ int shared_mem[];\n    \n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[(blockDim.x * blockDim.x)];\n\n    // it's a row ...\n\n    // abs row index \n    int i = BLOCK_START(t, blockDim.x) + threadIdx.x;    \n    // abs col index   \n    int j = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.y + ((blockIdx.x >= t) ? blockDim.x : 0); \n\n    // the block where I am working\n    block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[i*n + j];\n\n    // the self-dependent block already calculated in this round\n    block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        ((BLOCK_START(t, blockDim.x) + threadIdx.x) * n) + (BLOCK_START(t, blockDim.x) + threadIdx.y)\n    ];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        // Because we are doing rows:\n        // -    matrix[i,abs_k] is in block_t_t_shared[threadIdx.x,k]\n        // -    matrix[abs_k,j] is in block_i_j_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[threadIdx.x*blockDim.x + k], \n            block_i_j_shared[k*blockDim.x + threadIdx.y], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y]) {\n            block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[i*n + j] = block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y];\n}\n\n__global__ void execute_round_device_v_2_0_phase_2_col(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  U1  U2  U3  D1  D2\n    //  (trasposed)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // it's a column ...\n\n    // abs row index \n    int i = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.x + ((blockIdx.x >= t) ? blockDim.x : 0);\n    // abs col index \n    int j = BLOCK_START(t, blockDim.x) + threadIdx.y;\n\n    // the block where I am working\n    block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[i*n + j];\n\n    // the self-dependent block already calculated in this round\n    block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        ((BLOCK_START(t, blockDim.x) + threadIdx.x) * n) + (BLOCK_START(t, blockDim.x) + threadIdx.y)\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n        \n        // Because we are doing columns:\n        // -    matrix[i,k] is in block_i_j_shared[threadIdx.x,k]\n        // -    matrix[k,j] is in block_t_t_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_i_j_shared[threadIdx.x*blockDim.x + k], \n            block_t_t_shared[k*blockDim.x + threadIdx.y], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y]) {\n            block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[i*n + j] = block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y];\n}\n\n\n__global__ void execute_round_device_v_2_0_phase_3(int *matrix, int n, int t) {\n\n    // Launched blocks and correspondent position in the matrix\n\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  DL  DL  DL  DR  DR\n    //  DL  DL  DL  DR  DR\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_t_shared = &shared_mem[0];\n    int* block_t_j_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // abs row index\n    int i = threadIdx.x + blockIdx.x * blockDim.x + ((blockIdx.x >= t) ? blockDim.x : 0);\n    // abs col index\n    int j = threadIdx.y + blockIdx.y * blockDim.y + ((blockIdx.y >= t) ? blockDim.x : 0);\n    \n    // since the cell i,j is read and written only by this thread\n    // there is no need to copy its value to shared memory we can just us a local variable\n    int cell_i_j = matrix[i*n + j];\n        \n    // In phase 3 I copy in two portions of my shared memory\n    // the block corresponding to (t, this column) and (this row, t)\n    block_i_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        i*n + (BLOCK_START(t, blockDim.x) + threadIdx.y)\n    ];\n    block_t_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        ((BLOCK_START(t, blockDim.x) + threadIdx.x) * n) + j\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_i_t_shared[threadIdx.x*blockDim.x + k],\n            block_t_j_shared[k*blockDim.x + threadIdx.y],\n            INF\n        ); \n\n        if (using_k_path < cell_i_j) {\n            cell_i_j = using_k_path;\n        }\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[i*n + j] = cell_i_j;\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.347778Z","iopub.execute_input":"2022-08-20T10:29:35.348187Z","iopub.status.idle":"2022-08-20T10:29:35.362832Z","shell.execute_reply.started":"2022-08-20T10:29:35.348152Z","shell.execute_reply":"2022-08-20T10:29:35.361859Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_2_1_ERROR.cu\n\n#include \"include/include_needed_libraries.cuh\"\n\n//main device code\nvoid floyd_warshall_blocked_device_v_2_1f(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_2_1f_phase_1(int *matrix, int n);\n__global__ void execute_round_device_v_2_1f_phase_2_row(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_1f_phase_2_col(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_1f_phase_3(int *matrix, int n, int t);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_2_1f);\n\n}\n\nvoid floyd_warshall_blocked_device_v_2_1f(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n * n* sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n\n    // phase 1: all the self-dependent blocks made in parallel before starting the rounds \n    // dim3 num_blocks_phase_1(1, 1);\n    dim3 threads_per_block_phase_1(B, B);\n\n    execute_round_device_v_2_1f_phase_1<<<num_rounds, threads_per_block_phase_1, B*B*sizeof(int)>>>(dev_rand_matrix, n);\n    HANDLE_ERROR(cudaDeviceSynchronize());\n     \n    for(int t = 0; t < num_rounds; t++) { \n        \n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        // dim3 num_blocks_phase_2(1, num_rounds-1);  \n\n        execute_round_device_v_2_1f_phase_2_row<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        execute_round_device_v_2_1f_phase_2_col<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n\n        execute_round_device_v_2_1f_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n\n__global__ void execute_round_device_v_2_1f_phase_1(int *matrix, int n) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t1  t2  t3  t4  t5  t6\n    // (trasposed)\n\n    //  t1  .   .   .   .   . \n    //  .   t2  .   .   .   . \n    //  .   .   t3  .   .   . \n    //  .   .   .   t4  .   .\n    //  .   .   .   .   t5  . \n    //  .   .   .   .   .   t6\n\n    extern __shared__ int block_t_t_shared[];\n\n    int i = threadIdx.x + blockIdx.x * blockDim.x;  // row abs index\n    int j = threadIdx.y + blockIdx.x * blockDim.x;  // col abs index\n\n    block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[i*n + j];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[threadIdx.x*blockDim.x + k], \n            block_t_t_shared[k*blockDim.x + threadIdx.y], \n            INF\n        ); \n\n        if (using_k_path < block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y]) {\n            block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = using_k_path;\n        }\n        \n        __syncthreads();\n    }\n\n    matrix[i*n + j] = block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y];\n}\n\n__global__ void execute_round_device_v_2_1f_phase_2_row(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  L1  L2  L3  R1  R2      \n    //  (trasposed)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    extern __shared__ int shared_mem[];\n    \n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[(blockDim.x * blockDim.x)];\n\n    // it's a row ...\n\n    // abs row index \n    int i = BLOCK_START(t, blockDim.x) + threadIdx.x;    \n    // abs col index   \n    int j = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.y + ((blockIdx.x >= t) ? blockDim.x : 0); \n\n    // the block where I am working\n    block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[i*n + j];\n\n    // the self-dependent block already calculated in this round\n    block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        ((BLOCK_START(t, blockDim.x) + threadIdx.x) * n) + (BLOCK_START(t, blockDim.x) + threadIdx.y)\n    ];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        // Because we are doing rows:\n        // -    matrix[i,abs_k] is in block_t_t_shared[threadIdx.x,k]\n        // -    matrix[abs_k,j] is in block_i_j_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[threadIdx.x*blockDim.x + k], \n            block_i_j_shared[k*blockDim.x + threadIdx.y], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y]) {\n            block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[i*n + j] = block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y];\n}\n\n__global__ void execute_round_device_v_2_1f_phase_2_col(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  U1  U2  U3  D1  D2\n    //  (trasposed)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // it's a column ...\n\n    // abs row index \n    int i = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.x + ((blockIdx.x >= t) ? blockDim.x : 0);\n    // abs col index \n    int j = BLOCK_START(t, blockDim.x) + threadIdx.y;\n\n    // the block where I am working\n    block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[i*n + j];\n\n    // the self-dependent block already calculated in this round\n    block_t_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        ((BLOCK_START(t, blockDim.x) + threadIdx.x) * n) + (BLOCK_START(t, blockDim.x) + threadIdx.y)\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n        \n        // Because we are doing columns:\n        // -    matrix[i,k] is in block_i_j_shared[threadIdx.x,k]\n        // -    matrix[k,j] is in block_t_t_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_i_j_shared[threadIdx.x*blockDim.x + k], \n            block_t_t_shared[k*blockDim.x + threadIdx.y], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y]) {\n            block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[i*n + j] = block_i_j_shared[threadIdx.x*blockDim.x + threadIdx.y];\n}\n\n\n__global__ void execute_round_device_v_2_1f_phase_3(int *matrix, int n, int t) {\n\n    // Launched blocks and correspondent position in the matrix\n\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  DL  DL  DL  DR  DR\n    //  DL  DL  DL  DR  DR\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_t_shared = &shared_mem[0];\n    int* block_t_j_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // abs row index\n    int i = threadIdx.x + blockIdx.x * blockDim.x + ((blockIdx.x >= t) ? blockDim.x : 0);\n    // abs col index\n    int j = threadIdx.y + blockIdx.y * blockDim.y + ((blockIdx.y >= t) ? blockDim.x : 0);\n    \n    // since the cell i,j is read and written only by this thread\n    // there is no need to copy its value to shared memory we can just us a local variable\n    int cell_i_j = matrix[i*n + j];\n        \n    // In phase 3 I copy in two portions of my shared memory\n    // the block corresponding to (t, this column) and (this row, t)\n    block_i_t_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        i*n + (BLOCK_START(t, blockDim.x) + threadIdx.y)\n    ];\n    block_t_j_shared[threadIdx.x*blockDim.x + threadIdx.y] = matrix[\n        ((BLOCK_START(t, blockDim.x) + threadIdx.x) * n) + j\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_i_t_shared[threadIdx.x*blockDim.x + k],\n            block_t_j_shared[k*blockDim.x + threadIdx.y],\n            INF\n        ); \n\n        if (using_k_path < cell_i_j) {\n            cell_i_j = using_k_path;\n        }\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[i*n + j] = cell_i_j;\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.365092Z","iopub.execute_input":"2022-08-20T10:29:35.365832Z","iopub.status.idle":"2022-08-20T10:29:35.379112Z","shell.execute_reply.started":"2022-08-20T10:29:35.365792Z","shell.execute_reply":"2022-08-20T10:29:35.378243Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_2_2.cu\n\n#include \"include/include_needed_libraries.cuh\"\n#include \"include/lcm.hpp\"\n\n#define ARR_MATRIX_INDEX(i,j,n) (i*n+j)\n#define ARR_MATRIX_INDEX_TRASP(i,j,n) (i+n*j)\n\n#define SHARED_BANK_N_INT 32\n#define ARR_MATRIX_INDEX_BANK_CONFLICT(i, j, n, handle_bank_conflict) (i*n + j + (handle_bank_conflict ? i : 0))\n#define ARR_MATRIX_SIZE_BANK_CONFICT(B,handle_bank_conflict) (B*B + (handle_bank_conflict ? (B-1) : 0))\n\n//main device code\nvoid floyd_warshall_blocked_device_v_2_2(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_2_2_phase_1(int *matrix, int n, int t, bool handle_bank_conflict);\n__global__ void execute_round_device_v_2_2_phase_2_row(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_2_phase_2_col(int *matrix, int n, int t);\n__global__ void execute_round_device_v_2_2_phase_3(int *matrix, int n, int t);\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_2_2);\n}\n\nvoid floyd_warshall_blocked_device_v_2_2(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed mmax block size\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n*n*sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B;\n\n    bool bank_conflict_phase_1 = lcm(SHARED_BANK_N_INT, B) <= (B-1)*B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_2_2_phase_1<<<\n            num_blocks_phase_1, \n            threads_per_block_phase_1, \n            ARR_MATRIX_SIZE_BANK_CONFICT(B, bank_conflict_phase_1)*sizeof(int)\n            >>>(dev_rand_matrix, n, t, bank_conflict_phase_1);\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        // dim3 num_blocks_phase_2(1, num_rounds-1);  \n\n        execute_round_device_v_2_2_phase_2_row<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        execute_round_device_v_2_2_phase_2_col<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n\n        execute_round_device_v_2_2_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n}\n\n\n__global__ void execute_round_device_v_2_2_phase_1(int *matrix, int n, int t, bool handle_bank_conflict) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    extern __shared__ int block_t_t_shared[];\n\n    int i = threadIdx.x + t * blockDim.x;  // row abs index\n    int j = threadIdx.y + t * blockDim.x;  // col abs index\n\n    block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, k, blockDim.x, handle_bank_conflict)], \n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(k, threadIdx.y, blockDim.x, handle_bank_conflict)], \n            INF\n        ); \n\n        if (using_k_path < block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)]) {\n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)] = using_k_path;\n        }\n        \n        __syncthreads();\n    }\n\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)];\n}\n\n__global__ void execute_round_device_v_2_2_phase_2_row(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  L1  L2  L3  R1  R2      \n    //  (trasposed)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    extern __shared__ int shared_mem[];\n    \n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[(blockDim.x * blockDim.x)];\n\n    // it's a row ...\n\n    // abs row index \n    int i = BLOCK_START(t, blockDim.x) + threadIdx.x;    \n    // abs col index   \n    int j = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.y + ((blockIdx.x >= t) ? blockDim.x : 0); \n\n    // the block where I am working\n    block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    // the self-dependent block already calculated in this round (transposed to avoid bank conflict)\n    block_t_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(\n            (BLOCK_START(t, blockDim.x) + threadIdx.x), \n            (BLOCK_START(t, blockDim.x) + threadIdx.y), \n            n\n        )\n    ];\n\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        // Because we are doing rows:\n        // -    matrix[i,abs_k] is in block_t_t_shared[threadIdx.x,k]\n        // -    matrix[abs_k,j] is in block_i_j_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)], \n            block_i_j_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)]) {\n            block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)];\n}\n\n__global__ void execute_round_device_v_2_2_phase_2_col(int *matrix, int n, int t) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  U1  U2  U3  D1  D2\n    //  (trasposed)\n\n    //  .   .   .   U1  .   .\n    //  .   .   .   U2  .   .\n    //  .   .   .   U3  .   .\n    //  L1  L2  L3  -   R1  R2\n    //  .   .   .   D1  .   .\n    //  .   .   .   D2  .   .\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // it's a column ...\n\n    // abs row index \n    int i = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.x + ((blockIdx.x >= t) ? blockDim.x : 0);\n    // abs col index \n    int j = BLOCK_START(t, blockDim.x) + threadIdx.y;\n\n    // the block where I am working (transposed to avoid bank conflict)\n    block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    // the self-dependent block already calculated in this round \n    block_t_t_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(\n            (BLOCK_START(t, blockDim.x) + threadIdx.x), \n            (BLOCK_START(t, blockDim.x) + threadIdx.y), \n            n\n        )\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n        \n        // Because we are doing columns:\n        // -    matrix[i,k] is in block_i_j_shared[threadIdx.x,k]\n        // -    matrix[k,j] is in block_t_t_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)], \n            block_t_t_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)]) {\n            block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)];\n}\n\n\n__global__ void execute_round_device_v_2_2_phase_3(int *matrix, int n, int t) {\n\n    // Launched blocks and correspondent position in the matrix\n\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  UL  UL  UL  UR  UR\n    //  DL  DL  DL  DR  DR\n    //  DL  DL  DL  DR  DR\n\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR\n    //  UL  UL  UL  -   UR  UR  \n    //  -   -   -   -   -   - \n    //  DL  DL  DL  -   DR  DR\n    //  DL  DL  DL  -   DR  DR\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_t_shared = &shared_mem[0];\n    int* block_t_j_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // abs row index\n    int i = threadIdx.x + blockIdx.x * blockDim.x + ((blockIdx.x >= t) ? blockDim.x : 0);\n    // abs col index\n    int j = threadIdx.y + blockIdx.y * blockDim.y + ((blockIdx.y >= t) ? blockDim.x : 0);\n    \n    // since the cell i,j is read and written only by this thread\n    // there is no need to copy its value to shared memory we can just us a local variable\n    int cell_i_j = matrix[ARR_MATRIX_INDEX(i, j, n)];\n        \n    // In phase 3 I copy in two portions of my shared memory\n    // the block corresponding to (t, this column) and (this row, t). \n\n    // (this row, t) is transposed to prevent bank conflict\n\n    block_i_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(i, (BLOCK_START(t, blockDim.x) + threadIdx.y), n)\n    ];\n    block_t_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX((BLOCK_START(t, blockDim.x) + threadIdx.x), j, n)\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_i_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)],\n            block_t_j_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)],\n            INF\n        ); \n\n        if (using_k_path < cell_i_j) {\n            cell_i_j = using_k_path;\n        }\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = cell_i_j;\n}\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.380990Z","iopub.execute_input":"2022-08-20T10:29:35.381743Z","iopub.status.idle":"2022-08-20T10:29:35.396059Z","shell.execute_reply.started":"2022-08-20T10:29:35.381704Z","shell.execute_reply":"2022-08-20T10:29:35.395073Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_3_0.cu\n\n#include \"include/include_needed_libraries.cuh\"\n#include \"include/lcm.hpp\"\n\n#define ARR_MATRIX_INDEX(i,j,n) (i*n+j)\n#define ARR_MATRIX_INDEX_TRASP(i,j,n) (i+n*j)\n\n#define SHARED_BANK_N_INT 32\n#define ARR_MATRIX_INDEX_BANK_CONFLICT(i, j, n, handle_bank_conflict) (i*n + j + (handle_bank_conflict ? i : 0))\n#define ARR_MATRIX_SIZE_BANK_CONFICT(B,handle_bank_conflict) (B*B + (handle_bank_conflict ? (B-1) : 0))\n\n//main device code\nvoid floyd_warshall_blocked_device_v_3_0(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_3_0_phase_1(int *matrix, int n, int t, bool handle_bank_conflict);\n\n__global__ void execute_round_device_v_3_0_phase_2_row_portion(int *matrix, int n, int t, int start_col);\n__global__ void execute_round_device_v_3_0_phase_2_col_portion(int *matrix, int n, int t, int start_row);\n__global__ void execute_round_device_v_3_0_phase_3_portion(int *matrix, int n, int t, int start_row, int start_col);\n\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_3_0);\n}\n\nvoid floyd_warshall_blocked_device_v_3_0(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed max block size\n\n    cudaStream_t streams[4];\n    for (int i=0; i<4; i++) {\n        cudaStreamCreate(&streams[i]);\n    }\n\n    int *dev_rand_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_rand_matrix, n*n*sizeof(int)));\n    HANDLE_ERROR(cudaMemcpy(dev_rand_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int num_rounds = n/B; \n\n    bool bank_conflict_phase_1 = lcm(SHARED_BANK_N_INT, B) <= (B-1)*B;\n     \n    for(int t = 0; t < num_rounds; t++) { \n\n        //arr_execute_round(int *matrix, int n, int t, int row, int col, int B)\n\n        //phase 1: self-dependent block\n        dim3 num_blocks_phase_1(1, 1);\n        dim3 threads_per_block_phase_1(B, B);\n\n        execute_round_device_v_3_0_phase_1<<<\n            num_blocks_phase_1, \n            threads_per_block_phase_1, \n            ARR_MATRIX_SIZE_BANK_CONFICT(B, bank_conflict_phase_1)*sizeof(int), \n            streams[0]>>>(dev_rand_matrix, n, t, bank_conflict_phase_1);\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 2: all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        // dim3 num_blocks_phase_2(1, num_rounds-1);  \n\n        // execute_round_device_v_3_0_phase_2_row<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n        // execute_round_device_v_3_0_phase_2_col<<<num_rounds-1, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n\n        // up \n        execute_round_device_v_3_0_phase_2_col_portion<<<\n            t, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[0]>>>(dev_rand_matrix, n, t, 0);\n\n        // left\n        execute_round_device_v_3_0_phase_2_row_portion<<<\n            t, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[1]>>>(dev_rand_matrix, n, t, 0);\n\n        // down\n        execute_round_device_v_3_0_phase_2_col_portion<<<\n            num_rounds-1-t, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[2]>>>(dev_rand_matrix, n, t, t+1);\n\n        // right\n        execute_round_device_v_3_0_phase_2_row_portion<<<\n            num_rounds-1-t, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[3]>>>(dev_rand_matrix, n, t, t+1);\n\n\n        HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n\n        // dim3 num_blocks_phase_3(num_rounds-1, num_rounds-1); \n        // execute_round_device_v_3_0_phase_3<<<num_blocks_phase_3, threads_per_block_phase_1, 2*B*B*sizeof(int)>>>(dev_rand_matrix, n, t);\n\n        dim3 num_blocks_phase_3_ul(t, t);\n        execute_round_device_v_3_0_phase_3_portion<<<\n            num_blocks_phase_3_ul, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[0]>>>(dev_rand_matrix, n, t, 0, 0);\n\n        dim3 num_blocks_phase_3_dr(num_rounds-t-1, num_rounds-t-1); \n        execute_round_device_v_3_0_phase_3_portion<<<\n            num_blocks_phase_3_dr, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[1]>>>(dev_rand_matrix, n, t, t+1, t+1);\n\n        dim3 num_blocks_phase_3_ur(t, num_rounds-t-1); \n        execute_round_device_v_3_0_phase_3_portion<<<\n            num_blocks_phase_3_ur, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[2]>>>(dev_rand_matrix, n, t, 0, t+1);\n\n        dim3 num_blocks_phase_3_dl(num_rounds-t-1, t); \n        execute_round_device_v_3_0_phase_3_portion<<<\n            num_blocks_phase_3_dl, threads_per_block_phase_1, \n            2*B*B*sizeof(int), \n            streams[3]>>>(dev_rand_matrix, n, t, t+1, 0);\n\n        HANDLE_ERROR(cudaDeviceSynchronize()); \n    }\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaMemcpy(matrix, dev_rand_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n    HANDLE_ERROR(cudaFree(dev_rand_matrix));\n\n    for (int i=0; i<4; i++) {\n        HANDLE_ERROR(cudaStreamDestroy(streams[i]));\n    }\n}\n\n\n__global__ void execute_round_device_v_3_0_phase_1(int *matrix, int n, int t, bool handle_bank_conflict) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t\n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    extern __shared__ int block_t_t_shared[];\n\n    int i = threadIdx.x + t * blockDim.x;  // row abs index\n    int j = threadIdx.y + t * blockDim.x;  // col abs index\n\n    block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, k, blockDim.x, handle_bank_conflict)], \n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(k, threadIdx.y, blockDim.x, handle_bank_conflict)], \n            INF\n        ); \n\n        if (using_k_path < block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)]) {\n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)] = using_k_path;\n        }\n        \n        __syncthreads();\n    }\n\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)];\n}\n\n\n__global__ void execute_round_device_v_3_0_phase_2_row_portion(int *matrix, int n, int t, int start_col) {\nextern __shared__ int shared_mem[];\n    \n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[(blockDim.x * blockDim.x)];\n\n    // it's a row ...\n\n    // abs row index \n    int i = BLOCK_START(t, blockDim.x) + threadIdx.x;    \n    // abs col index   \n    int j = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.y + start_col * blockDim.x; \n\n    // the block where I am working\n    block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    // the self-dependent block already calculated in this round (transposed to avoid bank conflict)\n    block_t_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(\n            (BLOCK_START(t, blockDim.x) + threadIdx.x), \n            (BLOCK_START(t, blockDim.x) + threadIdx.y), \n            n\n        )\n    ];\n\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        // Because we are doing rows:\n        // -    matrix[i,abs_k] is in block_t_t_shared[threadIdx.x,k]\n        // -    matrix[abs_k,j] is in block_i_j_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)], \n            block_i_j_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)]) {\n            block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)];\n}\n\n\n__global__ void execute_round_device_v_3_0_phase_2_col_portion(int *matrix, int n, int t, int start_row) {\nextern __shared__ int shared_mem[];\n\n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // it's a column ...\n\n    // abs row index \n    int i = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.x + start_row * blockDim.x;\n    // abs col index \n    int j = BLOCK_START(t, blockDim.x) + threadIdx.y;\n\n    // the block where I am working (transposed to avoid bank conflict)\n    block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    // the self-dependent block already calculated in this round \n    block_t_t_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(\n            (BLOCK_START(t, blockDim.x) + threadIdx.x), \n            (BLOCK_START(t, blockDim.x) + threadIdx.y), \n            n\n        )\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n        \n        // Because we are doing columns:\n        // -    matrix[i,k] is in block_i_j_shared[threadIdx.x,k]\n        // -    matrix[k,j] is in block_t_t_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)], \n            block_t_t_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)]) {\n            block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)];\n}\n\n\n\n__global__ void execute_round_device_v_3_0_phase_3_portion(int *matrix, int n, int t, int start_row, int start_col) {\n\n    extern __shared__ int shared_mem[];\n\n    int* block_i_t_shared = &shared_mem[0];\n    int* block_t_j_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // abs row index\n    int i = threadIdx.x + blockIdx.x * blockDim.x + start_row * blockDim.x;\n    // abs col index\n    int j = threadIdx.y + blockIdx.y * blockDim.y + start_col * blockDim.y;\n\n    // printf(\"%d,%d\\n\",i,j);\n    \n    // since the cell i,j is read and written only by this thread\n    // there is no need to copy its value to shared memory we can just us a local variable\n    int cell_i_j = matrix[ARR_MATRIX_INDEX(i, j, n)];\n        \n    // In phase 3 I copy in two portions of my shared memory\n    // the block corresponding to (t, this column) and (this row, t). \n\n    // (this row, t) is transposed to prevent bank conflict\n\n    block_i_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(i, (BLOCK_START(t, blockDim.x) + threadIdx.y), n)\n    ];\n    block_t_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX((BLOCK_START(t, blockDim.x) + threadIdx.x), j, n)\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_i_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)],\n            block_t_j_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)],\n            INF\n        ); \n\n        if (using_k_path < cell_i_j) {\n            cell_i_j = using_k_path;\n        }\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = cell_i_j;\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.397989Z","iopub.execute_input":"2022-08-20T10:29:35.398756Z","iopub.status.idle":"2022-08-20T10:29:35.413982Z","shell.execute_reply.started":"2022-08-20T10:29:35.398719Z","shell.execute_reply":"2022-08-20T10:29:35.413036Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"%%file device_floyd_warshall_v_3_1.cu\n\n#include \"include/include_needed_libraries.cuh\"\n#include \"include/lcm.hpp\"\n#include <vector>\n\n#define ARR_MATRIX_INDEX(i,j,n) (i*n+j)\n#define ARR_MATRIX_INDEX_TRASP(i,j,n) (i+n*j)\n\n#define SHARED_BANK_N_INT 32\n#define ARR_MATRIX_INDEX_BANK_CONFLICT(i, j, n, handle_bank_conflict) (i*n + j + (handle_bank_conflict ? i : 0))\n#define ARR_MATRIX_SIZE_BANK_CONFICT(B,handle_bank_conflict) (B*B + (handle_bank_conflict ? (B-1) : 0))\n\n//main device code\nvoid floyd_warshall_blocked_device_v_3_1(int *matrix, int n, int B);\n\n//rounds code\n__global__ void execute_round_device_v_3_1_phase_1(int *matrix, int n, int t, bool handle_bank_conflict);\n\n__global__ void execute_round_device_v_3_1_phase_2_row_portion(int *matrix, int n, int t, int start_col, int end_col);\n__global__ void execute_round_device_v_3_1_phase_2_col_portion(int *matrix, int n, int t, int start_row, int end_row);\n__global__ void execute_round_device_v_3_1_phase_3_portion(int *matrix, int n, int t, int start_row, int start_col, int end_row, int end_col);\n\n\nint main(int argc, char *argv[]) {\n\n    return handle_arguments_and_execute(argc, argv, (void(*) (int*, int, int)) &floyd_warshall_blocked_device_v_3_1);\n}\n\ncudaKernelNodeParams cuda_graph_node_params_copy(cudaKernelNodeParams params) {\n    \n    cudaKernelNodeParams newParams = { 0 };\n\n    newParams.func = params.func;\n    newParams.blockDim = params.blockDim;\n    newParams.gridDim = params.gridDim;\n    newParams.kernelParams = params.kernelParams;\n    newParams.sharedMemBytes = params.sharedMemBytes;\n    newParams.extra = params.extra;\n\n    return newParams;\n}\n\n\nvoid floyd_warshall_blocked_device_v_3_1(int *matrix, int n, int B) {\n\n    assert(n%B == 0);                       // B must divide n\n    assert(B*B<=MAX_BLOCK_SIZE);            // B*B cannot exceed max block size\n\n    // init the graph i will use to do all rounds\n    cudaGraph_t graph;\n    cudaGraphCreate(&graph, 0);\n    std::vector<cudaGraphNode_t> nodeDependencies = {}; // Dependency vector \n\n    int *dev_matrix;\n    HANDLE_ERROR(cudaMalloc( (void**) &dev_matrix, n*n*sizeof(int)));\n\n    // HANDLE_ERROR(cudaMemcpy(dev_matrix, matrix, n*n*sizeof(int), cudaMemcpyHostToDevice));\n\n    cudaMemcpy3DParms copy_host_to_dev_params = {0};\n\n    copy_host_to_dev_params.srcArray = NULL;\n    copy_host_to_dev_params.srcPos = make_cudaPos(0, 0, 0);\n    copy_host_to_dev_params.srcPtr = make_cudaPitchedPtr((void*) matrix, n*n*sizeof(int), n*n, 1);\n    copy_host_to_dev_params.dstArray = NULL;\n    copy_host_to_dev_params.dstPos = make_cudaPos(0, 0, 0);\n    copy_host_to_dev_params.dstPtr = make_cudaPitchedPtr((void*) dev_matrix, n*n*sizeof(int), n*n, 1);\n    copy_host_to_dev_params.extent = make_cudaExtent(n*n*sizeof(float), 1, 1);\n    copy_host_to_dev_params.kind = cudaMemcpyHostToDevice;\n\n    cudaGraphNode_t copy_host_to_dev_node;\n\n    HANDLE_ERROR(cudaGraphAddMemcpyNode(\n        &copy_host_to_dev_node, graph, \n        nodeDependencies.data(), nodeDependencies.size(), \n        &copy_host_to_dev_params\n        ));\n\n\n    // number of rounds that will be executed\n    int num_rounds = n/B;\n\n    // check if there will be bank conflict in phase 1\n    bool bank_conflict_phase_1 = lcm(SHARED_BANK_N_INT, B) <= (B-1)*B;\n\n    // number of threads launched at each kernel \n    // (it has to be the same number because of the cuda graphs, \n    // the exceeding threads will end as firtst instruction)\n    dim3 num_blocks(max(num_rounds-1, 1), max(num_rounds-1, 1));\n    dim3 threads_per_block(B, B);\n\n    // a variable needed for calls which requires pointer args\n    int zero = 0;\n\n    // previous round nodes (so i can add them as dependency for the next)\n    cudaGraphNode_t prev_phase3_up_left_node,   prev_phase3_up_right_node, \n                    prev_phase3_down_left_node, prev_phase3_down_right_node;\n         \n    for(int t = 0; t < num_rounds; t++) { \n\n        // a variable needed for calls which requires pointer args\n        int t_plus_1 = t+1;\n\n        // ----------------------------------------------------------------------\n        // phase 1: self-dependent block\n\n        // execute_round_device_v_3_1_phase_1<<<\n        //     num_blocks, \n        //     threads_per_block, \n        //     ARR_MATRIX_SIZE_BANK_CONFICT(B, bank_conflict_phase_1)*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, bank_conflict_phase_1);\n\n        // HANDLE_ERROR(cudaDeviceSynchronize());\n\n        void* phase1_args[4] = { (void*) &dev_matrix, (void*) &n, (void*) &t, (void*) &bank_conflict_phase_1 };\n\n        cudaKernelNodeParams phase1_params;\n\n        phase1_params.func = (void*) execute_round_device_v_3_1_phase_1;\n        phase1_params.gridDim = num_blocks;\n        phase1_params.blockDim = threads_per_block;\n        phase1_params.sharedMemBytes = max(\n            ARR_MATRIX_SIZE_BANK_CONFICT(B, bank_conflict_phase_1)*sizeof(int), \n            2*B*B*sizeof(int)\n        );\n        phase1_params.sharedMemBytes = ARR_MATRIX_SIZE_BANK_CONFICT(B, bank_conflict_phase_1)*sizeof(int);\n        phase1_params.kernelParams = (void**) phase1_args;\n        phase1_params.extra = NULL;\n\n        nodeDependencies.clear(); \n        if (t > 0) {\n            // round after first should depend from previous\n            nodeDependencies.push_back(prev_phase3_up_left_node);\n            nodeDependencies.push_back(prev_phase3_up_right_node);\n            nodeDependencies.push_back(prev_phase3_down_right_node);\n            nodeDependencies.push_back(prev_phase3_down_left_node);\n        } else {\n            // first round depends \n            nodeDependencies.push_back(copy_host_to_dev_node);\n        }\n\n        cudaGraphNode_t phase1_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase1_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase1_params));\n\n        // HANDLE_ERROR(cudaDeviceSynchronize());\n\n        // ----------------------------------------------------------------------\n        // phase 2: row and cols\n        // all blocks that share a row or a column with the self dependent, so\n        //  -   all blocks just above or under t\n        //  -   all block at left and at right of t\n\n        nodeDependencies.clear();\n        nodeDependencies.push_back(phase1_node);\n\n        // up \n        // execute_round_device_v_3_1_phase_2_col_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, 0, t);\n\n        void* phase2_up_left_args[5] = { (void*) &dev_matrix, \n            &n, &t, &zero, &t };\n\n        cudaKernelNodeParams phase2_up_params = cuda_graph_node_params_copy(phase1_params);\n\n        phase2_up_params.func = (void*) execute_round_device_v_3_1_phase_2_col_portion;\n        phase2_up_params.sharedMemBytes = 2*B*B*sizeof(int);\n        phase2_up_params.kernelParams = (void**) phase2_up_left_args;\n\n        cudaGraphNode_t phase2_up_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase2_up_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase2_up_params\n        ));\n\n        // left\n        // execute_round_device_v_3_1_phase_2_row_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, 0, t);\n\n        cudaKernelNodeParams phase2_left_params = cuda_graph_node_params_copy(phase2_up_params);\n        phase2_left_params.func = (void*) execute_round_device_v_3_1_phase_2_row_portion;\n\n        cudaGraphNode_t phase2_left_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase2_left_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase2_left_params));\n\n        // down\n        // execute_round_device_v_3_1_phase_2_col_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, t+1, num_blocks);\n\n        cudaKernelNodeParams phase2_down_params = cuda_graph_node_params_copy(phase2_up_params);\n        void* phase2_down_right_args[5] = { (void*) &dev_matrix, \n            &n, &t, &t_plus_1, &num_rounds};\n        phase2_down_params.kernelParams = (void**) phase2_down_right_args;\n\n        cudaGraphNode_t phase2_down_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase2_down_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase2_down_params));\n\n        // right\n        // execute_round_device_v_3_1_phase_2_row_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, t+1, num_blocks);\n\n        cudaKernelNodeParams phase2_right_params = cuda_graph_node_params_copy(phase2_down_params);\n        phase2_right_params.func = (void*) execute_round_device_v_3_1_phase_2_row_portion;\n\n        cudaGraphNode_t phase2_right_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase2_right_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase2_right_params));\n\n        // HANDLE_ERROR(cudaDeviceSynchronize());\n        \n        // phase 3: all the remaining blocks, so all the blocks that don't share a row or a col with t\n        \n        // up-left\n        // execute_round_device_v_3_1_phase_3_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, 0, 0, t, t);\n\n        void* phase3_up_left_args[7] = {(void*) &dev_matrix, \n            &n, &t, &zero, &zero, &t, &t};\n\n        cudaKernelNodeParams phase3_up_left_params = cuda_graph_node_params_copy(phase2_up_params);\n\n        phase3_up_left_params.func = (void*) execute_round_device_v_3_1_phase_3_portion;\n        phase3_up_left_params.kernelParams = (void**) phase3_up_left_args;\n\n        nodeDependencies.clear();\n        nodeDependencies.push_back(phase2_up_node);\n        nodeDependencies.push_back(phase2_left_node);\n\n        cudaGraphNode_t phase3_up_left_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase3_up_left_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase3_up_left_params));\n\n        // up-right\n        // execute_round_device_v_3_1_phase_3_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, 0, t+1, t, num_rounds);\n\n        void* phase3_up_right_args[7] = {(void*) &dev_matrix, \n            &n, &t, &zero, &t_plus_1, &t, &num_rounds};\n\n        cudaKernelNodeParams phase3_up_right_params = cuda_graph_node_params_copy(phase3_up_left_params);\n        phase3_up_right_params.kernelParams = (void**) phase3_up_right_args;\n\n        nodeDependencies.clear();\n        nodeDependencies.push_back(phase2_up_node);\n        nodeDependencies.push_back(phase2_right_node);\n\n        cudaGraphNode_t phase3_up_right_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase3_up_right_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase3_up_right_params));\n\n        // down-right\n        // execute_round_device_v_3_1_phase_3_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, t+1, t+1, num_rounds, num_rounds);\n\n        void* phase3_down_right_args[7] = {(void*) &dev_matrix, \n            &n, &t, &t_plus_1, &t_plus_1, &num_rounds, &num_rounds};\n\n        cudaKernelNodeParams phase3_down_right_params = cuda_graph_node_params_copy(phase3_up_left_params);\n        phase3_down_right_params.kernelParams = (void**) phase3_down_right_args;\n\n        nodeDependencies.clear();\n        nodeDependencies.push_back(phase2_down_node);\n        nodeDependencies.push_back(phase2_right_node);\n\n        cudaGraphNode_t phase3_down_right_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase3_down_right_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase3_down_right_params));\n\n        // down-left\n        // execute_round_device_v_3_1_phase_3_portion<<<\n        //     num_blocks, threads_per_block, \n        //     2*B*B*sizeof(int), \n        //     graph_stream>>>(dev_matrix, n, t, t+1, 0, num_rounds, t);\n        \n        void* phase3_down_left_args[7] = {(void*) &dev_matrix, \n            &n, &t, &t_plus_1, &zero, &num_rounds, &t};\n\n        cudaKernelNodeParams phase3_down_left_params = cuda_graph_node_params_copy(phase3_up_left_params);\n        phase3_down_left_params.kernelParams = (void**) phase3_down_left_args;\n\n        nodeDependencies.clear();\n        nodeDependencies.push_back(phase2_down_node);\n        nodeDependencies.push_back(phase2_left_node);\n\n        cudaGraphNode_t phase3_down_left_node;\n\n        HANDLE_ERROR(cudaGraphAddKernelNode(\n            &phase3_down_left_node, graph, \n            nodeDependencies.data(), nodeDependencies.size(), \n            &phase3_down_left_params));\n\n        // HANDLE_ERROR(cudaDeviceSynchronize());   \n\n        // save phase 3 nodes\n        prev_phase3_up_left_node    = phase3_up_left_node;\n        prev_phase3_up_right_node   = phase3_up_right_node;\n        prev_phase3_down_right_node = phase3_down_right_node;\n        prev_phase3_down_left_node  = phase3_down_left_node;\n    }\n\n    // Add copy of final result from device to host (as graph)\n    // HANDLE_ERROR(cudaMemcpy(matrix, dev_matrix, n*n*sizeof(int), cudaMemcpyDeviceToHost));\n\n    cudaMemcpy3DParms copy_dev_to_host_params = {0};\n\n    copy_dev_to_host_params.srcArray = NULL;\n    copy_dev_to_host_params.srcPos = make_cudaPos(0, 0, 0);\n    copy_dev_to_host_params.srcPtr = make_cudaPitchedPtr((void*) dev_matrix, n*n*sizeof(int), n*n, 1);\n    copy_dev_to_host_params.dstArray = NULL;\n    copy_dev_to_host_params.dstPos = make_cudaPos(0, 0, 0);\n    copy_dev_to_host_params.dstPtr = make_cudaPitchedPtr((void*) matrix, n*n*sizeof(int), n*n, 1);\n    copy_dev_to_host_params.extent = make_cudaExtent(n*n*sizeof(float), 1, 1);\n    copy_dev_to_host_params.kind = cudaMemcpyDeviceToHost;\n\n    nodeDependencies.clear();\n    nodeDependencies.push_back(prev_phase3_up_left_node);\n    nodeDependencies.push_back(prev_phase3_up_right_node);\n    nodeDependencies.push_back(prev_phase3_down_right_node);\n    nodeDependencies.push_back(prev_phase3_down_left_node);\n\n    cudaGraphNode_t copy_dev_to_host_node;\n\n    HANDLE_ERROR(cudaGraphAddMemcpyNode(\n        &copy_dev_to_host_node, graph, \n        nodeDependencies.data(), nodeDependencies.size(), \n        &copy_dev_to_host_params\n        ));\n\n    // stream used for executing graph\n    cudaStream_t graph_stream;\n    cudaStreamCreate(&graph_stream);\n\n    // Instanciate and run graph\n    cudaGraphExec_t instance;\n    HANDLE_ERROR(cudaGraphInstantiate(&instance, graph, NULL, NULL, 0));\n    HANDLE_ERROR(cudaGraphLaunch(instance, graph_stream));\n    HANDLE_ERROR(cudaStreamSynchronize(graph_stream));\n\n    // Clean up\n    HANDLE_ERROR(cudaGraphExecDestroy(instance));\n    HANDLE_ERROR(cudaGraphDestroy(graph));\n\n    // HANDLE_ERROR(cudaDeviceSynchronize());  \n\n    HANDLE_ERROR(cudaFree(dev_matrix));\n\n    HANDLE_ERROR(cudaStreamDestroy(graph_stream));\n\n}\n\n\n__global__ void execute_round_device_v_3_1_phase_1(int *matrix, int n, int t, bool handle_bank_conflict) {\n\n    // Launched block and correspondent position in the matrix\n\n    //  t   -   -   -   -\n    //  -   -   -   -   -\n    //  -   -   -   -   -\n    //  -   -   -   -   -\n    //  -   -   -   -   -\n    \n\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n    //  .   .   .   t   .   .\n    //  .   .   .   .   .   . \n    //  .   .   .   .   .   . \n\n    if (blockIdx.x > 0 || blockIdx.y > 0)   return;\n\n    // if (threadIdx.x == 0 && threadIdx.y == 0) printf(\"(%d,%d) \", blockIdx.x, blockIdx.y);\n\n    extern __shared__ int block_t_t_shared[];\n\n    int i = threadIdx.x + t * blockDim.x;  // row abs index\n    int j = threadIdx.y + t * blockDim.x;  // col abs index\n\n    block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, k, blockDim.x, handle_bank_conflict)], \n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(k, threadIdx.y, blockDim.x, handle_bank_conflict)], \n            INF\n        ); \n\n        if (using_k_path < block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)]) {\n            block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)] = using_k_path;\n        }\n        \n        __syncthreads();\n    }\n\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_t_t_shared[ARR_MATRIX_INDEX_BANK_CONFLICT(threadIdx.x, threadIdx.y, blockDim.x, handle_bank_conflict)];\n}\n\n\n__global__ void execute_round_device_v_3_1_phase_2_row_portion(int *matrix, int n, int t, int start_col, int end_col) {\n    \n    if (blockIdx.x >= end_col-start_col)    return;\n    \n    extern __shared__ int shared_mem[];\n    \n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[(blockDim.x * blockDim.x)];\n\n    // it's a row ...\n\n    // abs row index \n    int i = BLOCK_START(t, blockDim.x) + threadIdx.x;    \n    // abs col index   \n    int j = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.y + start_col * blockDim.x; \n\n    // the block where I am working\n    block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    // the self-dependent block already calculated in this round (transposed to avoid bank conflict)\n    block_t_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(\n            (BLOCK_START(t, blockDim.x) + threadIdx.x), \n            (BLOCK_START(t, blockDim.x) + threadIdx.y), \n            n\n        )\n    ];\n\n\n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        // Because we are doing rows:\n        // -    matrix[i,abs_k] is in block_t_t_shared[threadIdx.x,k]\n        // -    matrix[abs_k,j] is in block_i_j_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_t_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)], \n            block_i_j_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)]) {\n            block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_i_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)];\n}\n\n\n__global__ void execute_round_device_v_3_1_phase_2_col_portion(int *matrix, int n, int t, int start_row, int end_row) {\n    \n    if (blockIdx.x >= end_row-start_row)    return;\n    \n    extern __shared__ int shared_mem[];\n\n    int* block_i_j_shared = &shared_mem[0];\n    int* block_t_t_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // it's a column ...\n\n    // abs row index \n    int i = BLOCK_START(blockIdx.x, blockDim.x) + threadIdx.x + start_row * blockDim.x;\n    // abs col index \n    int j = BLOCK_START(t, blockDim.x) + threadIdx.y;\n\n    // the block where I am working (transposed to avoid bank conflict)\n    block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[ARR_MATRIX_INDEX(i, j, n)];\n\n    // the self-dependent block already calculated in this round \n    block_t_t_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(\n            (BLOCK_START(t, blockDim.x) + threadIdx.x), \n            (BLOCK_START(t, blockDim.x) + threadIdx.y), \n            n\n        )\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n        \n        // Because we are doing columns:\n        // -    matrix[i,k] is in block_i_j_shared[threadIdx.x,k]\n        // -    matrix[k,j] is in block_t_t_shared[k,threadIdx.y]\n        int using_k_path = sum_if_not_infinite(\n            block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)], \n            block_t_t_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)], \n            INF\n        ); \n\n        if (using_k_path < block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)]) {\n            block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = using_k_path;\n        }\n\n        //printf(\"i:%d, j:%d, k:%d\\n\", i, j, k);\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = block_i_j_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)];\n}\n\n\n\n__global__ void execute_round_device_v_3_1_phase_3_portion(int *matrix, int n, int t, int start_row, int start_col, int end_row, int end_col) {\n\n    if (blockIdx.x >= end_row-start_row || blockIdx.y >= end_col-start_col)    return;\n    \n    extern __shared__ int shared_mem[];\n\n    int* block_i_t_shared = &shared_mem[0];\n    int* block_t_j_shared = &shared_mem[blockDim.x*blockDim.x];\n\n    // abs row index\n    int i = threadIdx.x + blockIdx.x * blockDim.x + start_row * blockDim.x;\n    // abs col index\n    int j = threadIdx.y + blockIdx.y * blockDim.y + start_col * blockDim.y;\n\n    // printf(\"%d,%d\\n\",i,j);\n    \n    // since the cell i,j is read and written only by this thread\n    // there is no need to copy its value to shared memory we can just us a local variable\n    int cell_i_j = matrix[ARR_MATRIX_INDEX(i, j, n)];\n        \n    // In phase 3 I copy in two portions of my shared memory\n    // the block corresponding to (t, this column) and (this row, t). \n\n    // (this row, t) is transposed to prevent bank conflict\n\n    block_i_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX(i, (BLOCK_START(t, blockDim.x) + threadIdx.y), n)\n    ];\n    block_t_j_shared[ARR_MATRIX_INDEX(threadIdx.x, threadIdx.y, blockDim.x)] = matrix[\n        ARR_MATRIX_INDEX((BLOCK_START(t, blockDim.x) + threadIdx.x), j, n)\n    ];\n    \n    __syncthreads();\n\n    // now k is iterating the relative indexind of (t,t) block \n    // in shared memory (instead of the abs position in matrix)\n    for (int k = 0; k < blockDim.x; k++) {\n\n        int using_k_path = sum_if_not_infinite(\n            block_i_t_shared[ARR_MATRIX_INDEX_TRASP(threadIdx.x, k, blockDim.x)],\n            block_t_j_shared[ARR_MATRIX_INDEX(k, threadIdx.y, blockDim.x)],\n            INF\n        ); \n\n        if (using_k_path < cell_i_j) {\n            cell_i_j = using_k_path;\n        }\n\n        __syncthreads();\n    }\n\n    // copy result in global memory\n    matrix[ARR_MATRIX_INDEX(i, j, n)] = cell_i_j;\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:35.417166Z","iopub.execute_input":"2022-08-20T10:29:35.417790Z","iopub.status.idle":"2022-08-20T10:29:35.439164Z","shell.execute_reply.started":"2022-08-20T10:29:35.417720Z","shell.execute_reply":"2022-08-20T10:29:35.438100Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"! make dev VERSION=1_3_pitch","metadata":{"execution":{"iopub.status.busy":"2022-08-20T11:00:27.347031Z","iopub.execute_input":"2022-08-20T11:00:27.347390Z","iopub.status.idle":"2022-08-20T11:00:32.667643Z","shell.execute_reply.started":"2022-08-20T11:00:27.347353Z","shell.execute_reply":"2022-08-20T11:00:32.666470Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":" ! ./bin/fwa_dev_v_1_3_pitch.out test","metadata":{"execution":{"iopub.status.busy":"2022-08-20T11:00:32.670283Z","iopub.execute_input":"2022-08-20T11:00:32.670715Z","iopub.status.idle":"2022-08-20T11:00:33.846485Z","shell.execute_reply.started":"2022-08-20T11:00:32.670675Z","shell.execute_reply":"2022-08-20T11:00:33.845151Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"! nvprof --profile-from-start on ./bin/fwa_dev_v_1_3_pitch.out perf -n=50 -b=10 -t=1","metadata":{"execution":{"iopub.status.busy":"2022-08-20T11:00:37.624640Z","iopub.execute_input":"2022-08-20T11:00:37.625325Z","iopub.status.idle":"2022-08-20T11:00:39.135412Z","shell.execute_reply.started":"2022-08-20T11:00:37.625287Z","shell.execute_reply":"2022-08-20T11:00:39.134235Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"! nvprof --csv --log-file csv/out.csv --normalized-time-unit us --profile-from-start off ./bin/fwa_dev_v_3_0.out perf -n=50 -b=10 -t=1","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:44.061724Z","iopub.execute_input":"2022-08-20T10:29:44.062058Z","iopub.status.idle":"2022-08-20T10:29:47.476266Z","shell.execute_reply.started":"2022-08-20T10:29:44.062026Z","shell.execute_reply":"2022-08-20T10:29:47.475148Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"! cat csv/out.csv","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:47.478109Z","iopub.execute_input":"2022-08-20T10:29:47.478849Z","iopub.status.idle":"2022-08-20T10:29:48.454972Z","shell.execute_reply.started":"2022-08-20T10:29:47.478809Z","shell.execute_reply":"2022-08-20T10:29:48.453826Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"%%file generate_and_print_n_b.cpp\n\n#include \"include/generate_n_b_couples.hpp\"\n#include \"include/macros.hpp\"\n\n#include \"time.h\"\n\nint main(int argc, char** argv) {\n\n    int seed = time(NULL);\n    srand(seed);\n\n    // define parameters\n    double to_multiply = 1;\n    int to_sum = 80;\n    int min_input_size = 80;\n    int max_input_size = 480;\n\n    //if blocking factors are calculated randomly\n    int min_blocking_factor = 2;\n    int max_num_of_b_per_n = 5;\n    int max_num_tests = 50;\n    //if blocking factors are given from argv\n    int* B;\n    if (argc > 1) {\n        B = (int *) malloc(sizeof(int) * (argc-1));\n    }\n\n    std::vector<std::pair<int, int>> list_of_all_n_b;\n\n    // print parameters\n    printf(\"to_multiply:\\t\\t%f\\n\", to_multiply);\n    printf(\"to_sum:\\t\\t\\t%d\\n\", to_sum);\n    printf(\"seed:\\t\\t\\t%d\\n\", seed);\n    printf(\"min_input_size:\\t\\t%d\\n\", min_input_size);\n    printf(\"max_input_size:\\t\\t%d\\n\", max_input_size);\n\n    if (argc == 1) {\n        // generate blocking factors randomly\n        printf(\"min_blocking_factor:\\t%d\\n\", min_blocking_factor);\n        printf(\"max_num_of_b_per_n:\\t%d\\n\", max_num_of_b_per_n);\n        printf(\"max_num_tests:\\t\\t%d\\n\", max_num_tests);\n        \n        // generate list randomly\n        list_of_all_n_b = generate_list_of_all_n_b(min_input_size, max_input_size, max_num_of_b_per_n, to_multiply, to_sum, min_blocking_factor, max_num_tests, seed);\n\n    } else {\n        // read blocking factors from argv\n        for (int i = 1; i < argc; i++) {\n            B[i-1] = atoi(argv[i]);\n        }\n        for (int n = min_input_size; n <= max_input_size; n = mmax(((int) (to_multiply * (double) n)) + to_sum, (n+1)) ) {\n            for (int i = 0; i < argc-1; i++) {\n                if (n % B[i] == 0) {\n                    list_of_all_n_b.push_back(std::make_pair(n, B[i]));\n                }   \n            }\n        }\n    }\n\n\n    // define output file name\n    std::string out_filename = \"csv/list_of_n_b.csv\";\n\n    // print list to file\n    print_list_to_file(list_of_all_n_b, out_filename);\n\n    // print file name\n    printf(\"\\noutput file:\\t\\t%s\\n\", out_filename.c_str());\n\n    return 0;\n    \n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:48.456676Z","iopub.execute_input":"2022-08-20T10:29:48.456998Z","iopub.status.idle":"2022-08-20T10:29:48.467952Z","shell.execute_reply.started":"2022-08-20T10:29:48.456968Z","shell.execute_reply":"2022-08-20T10:29:48.466515Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# ! make generate_n_b\n# ! echo\n# ! bin/generate_and_print_n_b.out 8 16 24 32\n# ! echo\n# ! cat csv/list_of_n_b.csv","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:48.470481Z","iopub.execute_input":"2022-08-20T10:29:48.471392Z","iopub.status.idle":"2022-08-20T10:29:48.476913Z","shell.execute_reply.started":"2022-08-20T10:29:48.471345Z","shell.execute_reply":"2022-08-20T10:29:48.476032Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"! rm -r csv\n! mkdir csv","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:48.480277Z","iopub.execute_input":"2022-08-20T10:29:48.480578Z","iopub.status.idle":"2022-08-20T10:29:50.441622Z","shell.execute_reply.started":"2022-08-20T10:29:48.480552Z","shell.execute_reply":"2022-08-20T10:29:50.440308Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"import re #regex\nimport os #operating system\nimport pandas as pd\nimport random\n\n# INPUT TEST DIMENSIONS\n\n# define and print command for compiling test dimension cpp file\nmake_test_dim_cmd = \"make generate_n_b\"\nprint(make_test_dim_cmd)\n# compile test dimension cpp file to bin file\nos.system(make_test_dim_cmd)\nprint()\n\n# generate all test dimensions\nos.system(\"bin/generate_and_print_n_b.out 8 16 24 32\")\nprint()\n\n# store test dimensions to csv and print them\ntest_dimensions = pd.read_csv('csv/list_of_n_b.csv')\nprint(\"test_dimensions:\")\nprint(test_dimensions)\nprint()\n\n# -----------------------------------------------------------------\n\n# ALGORITHM EXECUTION\n\ncuda_files = os.listdir()\n#print(files)\n\n# calculate and print the list of all random seeds\n#all_seeds = []\n#print(\"seeds:\")\n#for i in range(len(test_dimensions)) :\n#    rand = random.randint(0,9999999)\n#    all_seeds.append(rand)\n#    print(i, rand)\n#print()\n\n# use just one seed\nrand_seed = random.randint(0,9999999)\n\n\n# test each version\nfor file in cuda_files :\n\n    if re.match(\"device_floyd_warshall_v_.*\\.cu\", file) and (not re.match(\"device_floyd_warshall_v_.*_ERROR\\.cu\", file)):\n\n        # is a floyd_warshall cuda file\n\n        # obtain cuda file version\n        version = re.sub(\"^device_floyd_warshall_v_\", \"\", file)\n        version = re.sub(\"\\.cu$\", \"\", version)\n        \n        # define floyd warshall bin file\n        fw_bin = 'bin/fwa_dev_v_' + version + '.out'\n        \n        # print version, cuda file name, bin file name\n        print(f\"version:   {version}\")\n        print(f\"cuda file: {file}\")\n        print(f\"bin file:  {fw_bin}\\n\")\n\n        # define and print command for compiling cuda file to bin file\n        make_algorithm_cmd = \"make dev VERSION=\" + version\n        print(make_algorithm_cmd)\n        # compile test dimension cpp file to bin file\n        os.system(make_algorithm_cmd)\n        print()\n\n        # define parameters\n        #  - exec option: {'perf', 'test'}\n        exec_option='perf'\n        #  - number of tests for each couple (n,b)\n        t=1\n\n        for row in test_dimensions.iterrows() :\n\n            # foreach test dimension couple (n,b) :\n\n            i = row[0]\n            n = row[1][0]\n            b = row[1][1]\n            #print(n, b)\n            \n            csv_output = 'csv/fwa_dev_v_' + str(version) + '__n_' + str(n).zfill(3) + '__b_' + str(b).zfill(2) + \"__t_\" + str(t).zfill(2) + \".csv\"\n            print(f\"out file {i:02}: {csv_output}\")\n\n            launch_cmd = \"nvprof --csv --log-file \" + csv_output + \" --normalized-time-unit us --profile-from-start off ./\" + fw_bin + \" \" + exec_option + \" -t=\" + str(t) + \" -n=\" + str(n) + \" -b=\" + str(b) + \" -s=\" + str(rand_seed) #str(all_seeds[i])\n            print(launch_cmd)\n            os.system(launch_cmd)\n            print()\n\n        print(\"-----------------------------------------------------------------\")\n        print()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:29:50.443897Z","iopub.execute_input":"2022-08-20T10:29:50.444831Z","iopub.status.idle":"2022-08-20T10:36:32.755129Z","shell.execute_reply.started":"2022-08-20T10:29:50.444785Z","shell.execute_reply":"2022-08-20T10:36:32.754070Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"! ls -lh csv","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:36:32.756913Z","iopub.execute_input":"2022-08-20T10:36:32.757276Z","iopub.status.idle":"2022-08-20T10:36:33.742829Z","shell.execute_reply.started":"2022-08-20T10:36:32.757240Z","shell.execute_reply":"2022-08-20T10:36:33.741705Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('all_csv_output', 'zip', 'csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:36:33.745221Z","iopub.execute_input":"2022-08-20T10:36:33.745643Z","iopub.status.idle":"2022-08-20T10:36:33.781113Z","shell.execute_reply.started":"2022-08-20T10:36:33.745603Z","shell.execute_reply":"2022-08-20T10:36:33.780118Z"},"trusted":true},"execution_count":96,"outputs":[]}]}